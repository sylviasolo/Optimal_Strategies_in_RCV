{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Strategies in RCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We develop a computational framework to find optimal vote-addition strategies for each candidate -- if we want a candidate to place in the top $k$ of the election, what is the optimal (requiring the minimum number of additional ranked ballots) vote addition strategy? Our algorithmic framework is as follows (and as detailed in our paper), given $n$ candidates and $m$ unique voter ballots.\n",
    "\n",
    "(1) Each set of ballots induces a structure, referring to the outcome order (main-structure) and the round-specific elimination or winning order (sub-structure). Of course, given an initial set of votes, one can reach any alternative structure by adding enough votes.  Given a budget of $B$ additional votes, we first develop an algorithm to optimally (if possible) reach a given structure in $O(mn)$ time. Then, a binary search on the budget $B$ yields the optimal strategy to efficiently reach a given structure. \n",
    "\n",
    "However, with many candidates, there are a prohibitively large number of structures: there are $n!$ possible orders (main structures), of which the candidate would be in the top $k$ in $k \\times (n - 1)!$ main structures. Each main structure has $2^{n-1}$ sub-structures. Naively, then, finding an optimal strategy requires finding the minimum vote additions over $k \\times (n - 1)! \\times 2^{n-1}$ structures.  \n",
    "\n",
    "(2) Thus, we develop approaches to reduce the election size, without affecting the optimality of the calculated strategies. (a) Given a budget of $B$ additional votes and status quo vote data, we next give an algorithm with $O(mn^4)$ complexity that removes a set of irrelevant candidates who will be eliminated first regardless of how the $B$ votes are added. (b) We show that for any set of $k$ winners, there are only $\\sum_{j=1}^{k}$ $\\mathcal{C}^n_k$ feasible substructures. Then, we show how to reduce the number of substructures further given status quo vote data. We give an algorithm with $O(mn^2)$ complexity that reduces the number of feasible sub-structures that can lead to an optimal win. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations, groupby, permutations, product\n",
    "import time \n",
    "from copy import deepcopy\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "import seaborn as sns\n",
    "from operator import itemgetter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basic operations- generating voter data, doing permutations etc\n",
    "\n",
    "#a function for checking if two lists have any common elements\n",
    "def common_member(a, b): \n",
    "    a_set = set(a)\n",
    "    b_set = set(b)\n",
    "    if len(a_set.intersection(b_set)) > 0:\n",
    "        return(True)\n",
    "    return(False)  \n",
    "\n",
    "#given a list of candidates, this gives all possible orderings- n! in total\n",
    "def main_structures(candidates):\n",
    "    PotentialSets = [list(perm) for perm in permutations(candidates, len(candidates))]\n",
    "    return PotentialSets\n",
    "\n",
    "#returns a list of main strs for given list of winners\n",
    "def str_for_given_winners(winners, candidates):\n",
    "    losers = [item for item in candidates if item not in winners]\n",
    "    PotentialSets=[]\n",
    "\n",
    "    for perm_w in permutations(winners, len(winners)):\n",
    "        for perm_l in permutations(losers, len(losers)):\n",
    "            PotentialSets.append(list(perm_w)+list(perm_l))\n",
    "    return PotentialSets\n",
    "\n",
    "#returns a list of main strs for given list of losers\n",
    "def str_for_given_losers(losers, candidates):\n",
    "    winners = [item for item in candidates if item not in losers]\n",
    "    PotentialSets=[]\n",
    "\n",
    "    for perm_w in permutations(winners, len(winners)):\n",
    "        for perm_l in permutations(losers, len(losers)):\n",
    "            PotentialSets.append(list(perm_w)+list(perm_l))\n",
    "    return PotentialSets\n",
    "    \n",
    "#returns a list of main strs for given list of winners and losers\n",
    "def str_for_given_winners_losers(winners, candidates, losers):\n",
    "    middle = [item for item in candidates if item not in winners or losers]\n",
    "    PotentialSets=[]\n",
    "\n",
    "    for perm_w in permutations(winners, len(winners)):\n",
    "        for perm_l in permutations(losers, len(losers)):\n",
    "            for perm_m in permutations(middle, len(middle)):\n",
    "                PotentialSets.append(list(perm_w)+list(perm_m)+list(perm_l))\n",
    "    return PotentialSets\n",
    "    \n",
    "\n",
    "#given a list of candidates, this gives all possible W/L round result types- 2^(n-1) in total\n",
    "def sub_structures(candidates):\n",
    "    l = len(candidates)-1\n",
    "    results = list(product([0,1],repeat=l))\n",
    "    roundresults = [list(ele)+[1] for ele in results]\n",
    "    return roundresults\n",
    "\n",
    "# Generate all possible combinations of 0 and 1 with z zeros at the beginning and (l - z) zeros in the middle\n",
    "# thm that bounds the min number of initial losses\n",
    "def sub_structures_specific(candidates, z):\n",
    "    l = len(candidates) - 1\n",
    "    \n",
    "    prefix = [0] * z\n",
    "    middle = list(product([0, 1], repeat=l - z))\n",
    "    suffix = [1]\n",
    "    \n",
    "    # Combine the prefix, middle, and suffix to form the final combinations\n",
    "    results = [prefix + list(ele) + suffix for ele in middle]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def sub_structures_at_most_k_ones_fixed_last(candidates, k):\n",
    "    \"\"\"\n",
    "    Returns all binary sequences of length len(candidates)\n",
    "    whose last bit is forced to 1 and which have at most k ones.\n",
    "    \"\"\"\n",
    "    n = len(candidates)\n",
    "    results = []\n",
    "    # We'll generate sequences of length n-1, then append 1\n",
    "    for bits in product([0, 1], repeat=n-1):\n",
    "        # The total number of ones includes the appended 1\n",
    "        if sum(bits) + 1 <= k:\n",
    "            results.append(list(bits) + [1])\n",
    "    return results\n",
    "\n",
    "# given a main and sub structure, this gives a dict and a list showing who wins/loses in each round, in the order.\n",
    "def create_structure(main, sub):\n",
    "    maincopy = deepcopy(main)\n",
    "    results = []\n",
    "    redict = {} # mapping candidates to their results in the round order.\n",
    "    for i in sub:\n",
    "        if i == 0:\n",
    "            res = maincopy.pop(-1)\n",
    "            results.append([res, i])\n",
    "        else:\n",
    "            res = maincopy.pop(0)\n",
    "            results.append([res, i])\n",
    "        redict[res] = i     \n",
    "    return results, redict\n",
    "\n",
    "# given a list showing who wins/loses in each round, this gives the main and sub structure\n",
    "def return_main_sub(results_list):\n",
    "    strt = deepcopy(results_list)\n",
    "    sub = [] # mapping candidates to their results in the round order.\n",
    "    win=[]\n",
    "    lose=[]\n",
    "    for i in strt:\n",
    "        if i[1]>0:\n",
    "            win= win +[i[0]]\n",
    "        else:\n",
    "            lose= [i[0]] +lose\n",
    "        sub.append(i[1])\n",
    "    main = win+lose\n",
    "    return main, sub\n",
    "\n",
    "\n",
    "#while transferring from the last candidate to the current ones, we may pass those through checked candidates\n",
    "#so here, we make permutations of checked candidates and add these paths between the transfers\n",
    "def make_perms_transfer(candidates):\n",
    "    perms_candidates = [] \n",
    "    for l in range(len(candidates)):\n",
    "        perms = [list(perm) for perm in permutations(candidates, l)]\n",
    "        perms_candidates = perms_candidates+perms\n",
    "    return perms_candidates\n",
    "\n",
    "# This is a general function for making all possible vote patterns of specified length, given the set of candidates. \n",
    "def make_perms(candidates, min_ballot_length=0):\n",
    "    perms_candidates = [] \n",
    "    for l in range(min_ballot_length, len(candidates)):\n",
    "        perms = [list(perm) for perm in permutations(candidates, l+1)]\n",
    "        perms_candidates = perms_candidates+perms\n",
    "    return perms_candidates\n",
    "\n",
    "# initiates a dict of all possible winner types\n",
    "def dict_perm_k(candidates, k):\n",
    "    dict_new = {}\n",
    "    for perm in permutations(candidates, k):\n",
    "        dict_new[''.join(list(perm))] = 0\n",
    "        \n",
    "    return dict_new\n",
    "\n",
    "# Returns the list of winners, given main str.\n",
    "def give_winners(main_st, k):\n",
    "    winners = main_st[0:k]\n",
    "    return winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basic dict operations- aggregation, non-aggregation, converting investment into complete aggr-data etc\n",
    "\n",
    "# takes data in (type, num) format through lists and returns it in a dict format, but non-aggregated. \n",
    "def non_agg_dict(Ballottypes, NumVoters):\n",
    "    stringballots = []\n",
    "    for ballot in Ballottypes:\n",
    "        ballotnew = ''.join(ballot)\n",
    "        stringballots.append(ballotnew)\n",
    "\n",
    "    non_aggre_voterdata_dict = dict(zip(stringballots, NumVoters))\n",
    "    return non_aggre_voterdata_dict\n",
    "\n",
    "#Take non-agg data and returns the complete aggr_dict.\n",
    "#creates a dict with all V variables, where V_{AB} includes total votes that have first and second choices as A and B.\n",
    "def agg_dict(candidates, non_aggre_voterdata):\n",
    "    aggre_v_dict = Counter()\n",
    "    permset = make_perms(candidates)\n",
    "\n",
    "    # Calculate the aggregation using Counter\n",
    "    for ballot in permset:\n",
    "        for i in range(len(ballot)):\n",
    "            v = ''.join(ballot[0:i+1])\n",
    "            aggre_v_dict[v] += non_aggre_voterdata.get(''.join(ballot), 0)\n",
    "\n",
    "    # Filter out keys with zero counts\n",
    "    final_dict = {x: y for x, y in aggre_v_dict.items() if y > 0}\n",
    "    return final_dict\n",
    "\n",
    "# converts any investment or ballot counts into aggregated investment\n",
    "def get_new_dict(my_dict):\n",
    "    new_dict = {}\n",
    "    \n",
    "    # Iterate through the keys and values in my_dict\n",
    "    for key, value in my_dict.items():\n",
    "        # Generate all possible substrings of the key\n",
    "        substrings = [key[:i+1] for i in range(len(key))]\n",
    "        \n",
    "        # Update the new_dict with the aggregated values for each substring\n",
    "        for substring in substrings:\n",
    "            new_dict[substring] = new_dict.get(substring, 0) + value\n",
    "    \n",
    "    # Filter out keys with zero counts\n",
    "    final_dict = {x: y for x, y in new_dict.items() if y > 0}\n",
    "    return final_dict\n",
    "\n",
    "\n",
    "## Given the investment and the original aggr_dict, this returns the final aggr_dict.\n",
    "def campaign_addition_dict(my_total_investment_dict, candidates, aggre_v_dict):\n",
    "    \n",
    "    my_total_investment_dict_d = deepcopy(my_total_investment_dict)\n",
    "    aggre_v_dict_d = deepcopy(aggre_v_dict)\n",
    "  \n",
    "    agg_total_investment_dict = get_new_dict(my_total_investment_dict_d)\n",
    "\n",
    "    for key in agg_total_investment_dict.keys():\n",
    "\n",
    "        aggre_v_dict_d[key] = aggre_v_dict_d.get(key,0) + math.ceil(agg_total_investment_dict.get(key,0))\n",
    "    \n",
    "    return aggre_v_dict_d\n",
    "\n",
    "## Given the investment and the original aggr_dict, this returns the final aggr_dict.\n",
    "def campaign_addition_dict_simple(my_total_investment_count, candidates, ballot_counts):\n",
    "    \n",
    "    my_total_investment_count_d = deepcopy(my_total_investment_count)\n",
    "    ballot_counts_d = deepcopy(ballot_counts)\n",
    "\n",
    "    for key in my_total_investment_count_d.keys():\n",
    "\n",
    "        ballot_counts_d[key] = ballot_counts_d.get(key,0) + math.ceil(my_total_investment_count_d.get(key,0))\n",
    "    \n",
    "    return ballot_counts_d\n",
    "\n",
    "## Reverse of aggregation operation. Given an aggregated dict, this gives a non-agg dict.\n",
    "def clean_aggre_dict_diff(anydict):\n",
    "    cleandict=deepcopy(anydict)\n",
    "    for key1 in cleandict.keys():\n",
    "        for key2 in cleandict.keys():\n",
    "            if key2[0:len(key1)]==key1 and key1!=key2:\n",
    "               \n",
    "                cleandict[key1] = cleandict[key1]-cleandict[key2]\n",
    "    final_dict = {x:y for x,y in cleandict.items() if y>0}\n",
    "    return final_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STV operations- navigating structures; finding optimal STV result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Core functions of STV elections- coding up information in round-update, decoding later from their format\n",
    "\n",
    "# After a round result (W/L) is reflected in checked_candidates, \n",
    "# this step updates the remaining vote banks by transfering the unused votes\n",
    "def roundupdate(structure, checked_candidates, remaining_candidates, olddict):\n",
    "    if len(checked_candidates)==0:\n",
    "        return olddict\n",
    "    currentdict = deepcopy(olddict)\n",
    "    last_candidate = checked_candidates[-1] #depends on whether the last result is W or L, update changes\n",
    "    \n",
    "    perms_checked_candidates = make_perms_transfer(checked_candidates)\n",
    "    \n",
    "    stvotelist = currentdict[last_candidate] #last candidate's total vote bank\n",
    "    for I_c in stvotelist:  #each set of votes that has a separate path to the last candidate\n",
    "        I = deepcopy(I_c) #copying so that the Q updates don't change the original list accounts\n",
    "        q = []\n",
    "        while I[-1][0]==1: #we remove the lists with [1,..] from vote banks because these are fractions\n",
    "            q1 = I.pop()\n",
    "            q = q+[q1] #all removed fractions are stored here and appended later\n",
    "        for j in remaining_candidates: # the vote banks of remaining candidates are updated here\n",
    "            for l in perms_checked_candidates: #for each permutation of checked candidates that gets appended in middle\n",
    "                if common_member(I, l) == False: #making sure the permutation candidates and the sets are distinct\n",
    "                    if structure[last_candidate]==0: #last round is an elimination\n",
    "                        Inew = I + l +[j]+ q \n",
    "                    else:    # last round is a win\n",
    "                        Inew = I + l +[j] + q + [[1, 'Q', stvotelist]] #append a list for the surplus fraction\n",
    "                    currentdict[j] =  currentdict[j]+[Inew]\n",
    "    return currentdict\n",
    "\n",
    "\n",
    "##Used to decode the previously coded descriptions in round_update. Gives dict containing numbers for current round.\n",
    "# using aggregated data, converts each path into a number that measures the votes this path contributes\n",
    "def decode_list(pathcopy, Q, aggre_v_dict):\n",
    "    path = deepcopy(pathcopy)\n",
    "    if path[-1][0]!=1:\n",
    "        value =  aggre_v_dict.get(''.join(path), 0)  \n",
    "        return value\n",
    "    Qlist = []\n",
    "    path2 = deepcopy(path)\n",
    "    while path2[-1][0]==1:\n",
    "        q_item = path2.pop()\n",
    "        Qlist.append(q_item)\n",
    "    tot = decode_list(path2, Q, aggre_v_dict)\n",
    "    for q_item in Qlist:\n",
    "        value = 0\n",
    "        for part in q_item[-1]:\n",
    "            value = value + decode_list(part, Q, aggre_v_dict)\n",
    "        tot = tot *max(0, ( 1 - Q/(value+0.001)))\n",
    "        #tot = tot *( 1 - Q/value)\n",
    "    return tot\n",
    "\n",
    "\n",
    "# using aggregated data, converts a dict with complete variable description to numerical data\n",
    "def decode_dict(currentdict, candidates, Q, aggre_v_dict):\n",
    "    newcurrentdict = {}\n",
    "    for candidate in candidates:\n",
    "        currentdict2 = deepcopy(currentdict)\n",
    "        v_list = currentdict2[candidate]\n",
    "        newcurrentdict[candidate] = round(sum(decode_list(path, Q, aggre_v_dict) for path in v_list),3)\n",
    "\n",
    "    return newcurrentdict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Produce optimal STV result ###\n",
    "\n",
    "\n",
    "# creates a short dict from decoded_dict-for only remaining candidates- and returns the next elimination/win\n",
    "# used in finding optimal STV result\n",
    "def give_next_candidate(decoded_dict, remaining_candidates, Q, rt, dt):    \n",
    "    short_decoded_dict = {can: decoded_dict[can] for can in remaining_candidates}\n",
    "        \n",
    "    # performs the next elimination/win and puts it in the checked_list\n",
    "    t1 = max(short_decoded_dict, key=short_decoded_dict.get)\n",
    "    t2 = min(short_decoded_dict, key=short_decoded_dict.get)\n",
    "    if decoded_dict[t1]>=Q:\n",
    "        t = t1\n",
    "        rt.append([t, 1])\n",
    "        dt[t] = 1\n",
    "    else:\n",
    "        t = t2\n",
    "        rt.append([t, 0])\n",
    "        dt[t] = 0\n",
    "    return t, rt, dt\n",
    "\n",
    "\n",
    "# for a given voter data, this produces the resulting optimal structure\n",
    "# a bit similar to process_structure_STV\n",
    "def STV_optimal_result(candidates, k, Q, aggre_v_dict):    \n",
    "\n",
    "    currentdict  = {can: [[can]] for can in candidates}\n",
    "\n",
    "    remaining_candidates = deepcopy(candidates)\n",
    "    checked_candidates = []\n",
    "    dt = {}\n",
    "    rt = []\n",
    "    \n",
    "    for i in range(len(candidates)):\n",
    "       \n",
    "        # for i'th round, takes the currentdict and updates according to current round of elimination/win\n",
    "        currentdict = roundupdate(dt, checked_candidates, remaining_candidates, currentdict)\n",
    "        \n",
    "        # once the variables are obtained for next round, this converts into numerical data\n",
    "        decoded_dict = decode_dict(currentdict, candidates, Q, aggre_v_dict)\n",
    "        \n",
    "        t, rt, dt = give_next_candidate(decoded_dict, remaining_candidates, Q, rt, dt)\n",
    "        \n",
    "        remaining_candidates.remove(t) \n",
    "        checked_candidates.append(t)\n",
    "        \n",
    "    return rt, dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##produce optimal social choice order for IRV or Single-winner RCV\n",
    "\n",
    "def IRV_optimal_result(cands, ballot_counts):\n",
    "    \n",
    "    candsnew= deepcopy(cands)\n",
    "    aggre_v_dict_mynew = get_new_dict(ballot_counts)\n",
    "    results=[]\n",
    "    \n",
    "    for i in range(len(candsnew)):\n",
    "        relevant_aggre_dict={}\n",
    "    \n",
    "        for c in candsnew:\n",
    "        \n",
    "            relevant_aggre_dict[c] =  aggre_v_dict_mynew.get(c, 0)\n",
    "            \n",
    "        worst_c = min(relevant_aggre_dict, key=relevant_aggre_dict.get)\n",
    "        \n",
    "        candsnew.remove(worst_c)\n",
    "        results.insert(0, worst_c)\n",
    "        # Initialize a dictionary for filtered data\n",
    "        filtered_data = {}\n",
    "\n",
    "        for key, value in ballot_counts.items():\n",
    "            new_key = ''.join(char for char in key if char not in results)\n",
    "\n",
    "            filtered_data[new_key] =   filtered_data.get(new_key, 0) + value\n",
    "            \n",
    "        filtered_data.pop('', None)\n",
    "        aggre_v_dict_mynew={}\n",
    "\n",
    "        aggre_v_dict_mynew = get_new_dict(filtered_data)\n",
    "        \n",
    "    return results\n",
    "    \n",
    "\n",
    "def STV_optimal_result_simple(cands, ballot_counts, k, Q):\n",
    "    \"\"\"\n",
    "    Compute the optimal social choice order for Single Transferable Vote (STV).\n",
    "\n",
    "    Args:\n",
    "        cands (list): List of candidates.\n",
    "        ballot_counts (dict): Dictionary where keys are ranked ballots (as strings) and values are counts.\n",
    "        k (int): Number of winners.\n",
    "\n",
    "    Returns:\n",
    "        list, dict: List of events with winners (1) and eliminations (0), and a dictionary summarizing the same.\n",
    "        collection/list of updated dicts of remaining votes in every round\n",
    "    \"\"\"\n",
    "    candsnew = deepcopy(cands)\n",
    "    aggre_v_dict_mynew = get_new_dict(ballot_counts)\n",
    "    results = []\n",
    "    event_log = []\n",
    "    result_dict = {c: 0 for c in cands}\n",
    "   \n",
    "    collection = []\n",
    "    current_round = 0\n",
    "    collection.append([ballot_counts, current_round])\n",
    "\n",
    "    # Calculate the Droop quota\n",
    "    total_votes = sum(ballot_counts.values())\n",
    "\n",
    "    while candsnew:  # Process all candidates until all are either winners or eliminated\n",
    "        current_round = current_round + 1 \n",
    "        relevant_aggre_dict = {}\n",
    "\n",
    "        # Calculate first-choice votes for remaining candidates\n",
    "        for c in candsnew:\n",
    "            relevant_aggre_dict[c] = aggre_v_dict_mynew.get(c, 0)\n",
    "\n",
    "        # Check if any candidate meets the quota\n",
    "        winner = None\n",
    "        for candidate, votes in relevant_aggre_dict.items():\n",
    "            if votes >= Q:  # Ensure only `k` winners\n",
    "                winner = max(relevant_aggre_dict, key=relevant_aggre_dict.get)\n",
    "            \n",
    "                event_log.append([winner, 1])\n",
    "                result_dict[winner] = 1\n",
    "                candsnew.remove(winner)\n",
    "\n",
    "                # Distribute surplus votes proportionally\n",
    "                surplus = votes - Q\n",
    "                if surplus > 0:\n",
    "                    transfer_weight = surplus / votes\n",
    "                    filtered_data_1 = {}\n",
    "\n",
    "                    for key, value in ballot_counts.items():\n",
    "                        if key.startswith(winner):\n",
    "                            new_key = key[1:]  # Remove the winner from the ballot\n",
    "                            filtered_data_1[new_key] = filtered_data_1.get(new_key, 0) + value * transfer_weight\n",
    "                        else:\n",
    "                            if winner in key:\n",
    "                                newkey = ''.join(char for char in key if char not in [winner])\n",
    "                                filtered_data_1[newkey] = filtered_data_1.get(newkey, 0) + value\n",
    "                            else:\n",
    "                                filtered_data_1[key] = filtered_data_1.get(key, 0) + value\n",
    "                        \n",
    "\n",
    "                filtered_data_1.pop('', None)\n",
    "                results.append(winner)\n",
    "                break\n",
    "\n",
    "        if winner is None:  # No candidate meets the quota, eliminate the lowest\n",
    "            if not relevant_aggre_dict:  # Check if relevant_aggre_dict is empty\n",
    "                break  # Exit the loop if no candidates remain\n",
    "        \n",
    "\n",
    "            loser = min(relevant_aggre_dict, key=relevant_aggre_dict.get)\n",
    "            candsnew.remove(loser)\n",
    "            event_log.append([loser, 0])\n",
    "            result_dict[loser] = 0\n",
    "            results.append(loser)\n",
    "\n",
    "            # Redistribute votes of the eliminated candidate\n",
    "            filtered_data_1 = {}\n",
    "\n",
    "            for key, value in ballot_counts.items():\n",
    "                if key.startswith(loser):\n",
    "                    new_key = key[1:]  # Remove the loser from the ballot\n",
    "                    filtered_data_1[new_key] = filtered_data_1.get(new_key, 0) + value\n",
    "                else:\n",
    "                    if loser in key:\n",
    "                        newkey = ''.join(char for char in key if char not in [loser])\n",
    "                        filtered_data_1[newkey] = filtered_data_1.get(newkey, 0) + value\n",
    "                    else:\n",
    "                        filtered_data_1[key] = filtered_data_1.get(key, 0) + value\n",
    "\n",
    "            filtered_data_1.pop('', None)\n",
    "\n",
    "        aggre_v_dict_mynew={}\n",
    "        ballot_counts = filtered_data_1\n",
    "        aggre_v_dict_mynew = get_new_dict(ballot_counts)\n",
    "        collection.append([ballot_counts, current_round])\n",
    "\n",
    "\n",
    "    return event_log, result_dict, collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing smart campaigns, holistically, for all rounds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Returns the campaign investment needed for a round, given budget. Returns false, if this is not possible.\n",
    "def add_campaign(log_campaign_list, main_st,  remaining_candidates, decoded_dict, Q, k, t, stdt, budget):\n",
    "    current_campaign_dict = {j:0 for j in main_st} \n",
    "          \n",
    "    if stdt[t]==1:\n",
    "        v = []\n",
    "        for candidate in remaining_candidates:\n",
    "            v.append(decoded_dict[candidate])\n",
    "        t_update = max(0,(max(v) - decoded_dict[t])+1, (Q - decoded_dict[t])+1)\n",
    "        if t_update>budget:\n",
    "            return {}, False\n",
    "        current_campaign_dict[t] = t_update\n",
    "    else: \n",
    "        for candidate in remaining_candidates:\n",
    "            \n",
    "            if decoded_dict[candidate] >= Q:\n",
    "                \n",
    "                return {}, False\n",
    "            else:\n",
    "                can_update = max(0, decoded_dict[t] - decoded_dict[candidate]+1)\n",
    "                if can_update>budget:\n",
    "                    return {}, False\n",
    "                current_campaign_dict[candidate] = can_update \n",
    "            \n",
    "    log_campaign_list.append(deepcopy(current_campaign_dict))\n",
    "\n",
    "    return log_campaign_list, True\n",
    "\n",
    "# Given a structure and voter data and an updated Q, this gives a round-wise campaign allocation requirement to \n",
    "# make the structure feasible. Provides fixed addition to be made in each round, by calling add_campaign.\n",
    "# This function doesn't utilitze the budget to fulfil the structural requirements. Just lists those.\n",
    "def process_campaign_STV(candidates, main, sub, k, Q, aggre_v_dict, budget):    \n",
    "    \n",
    "    strt, stdt = create_structure(main, sub)\n",
    "    currentdict  = {can: [[can]] for can in candidates}\n",
    "\n",
    "    remaining_candidates = list(stdt.keys())\n",
    "    checked_candidates = []\n",
    "    \n",
    "    CheckDicts = [] # list of additions each round should have, with each round addition in dict format for candidates\n",
    "    DecodedDicts = [] # list of how votes look according to given main and sub structure, in each round\n",
    "    status_list = []\n",
    "    log_campaign_list = []\n",
    "\n",
    "    for i in range(len(candidates)-1):\n",
    "        \n",
    "        # for i'th round, takes the currentdict and updates according to current round of elimination/win\n",
    "        currentdict = roundupdate(stdt, checked_candidates, remaining_candidates, currentdict)\n",
    "        \n",
    "        # once the variables are obtained for next round, this converts into numerical data\n",
    "        decoded_dict = decode_dict(currentdict, candidates, Q, aggre_v_dict)\n",
    "\n",
    "        \n",
    "        # performs the next elimination/win and puts it in the checked_list\n",
    "        t = remaining_candidates.pop(0) \n",
    "        checked_candidates.append(t)\n",
    "        \n",
    "        # checks if the next elimination/win is alright and if not, gives the addition that can make it right\n",
    "        log_campaign_list, status = add_campaign(log_campaign_list, main, remaining_candidates, decoded_dict, Q, k, t, stdt, budget)\n",
    "        if status==False:\n",
    "            return {}, [], [], [False]\n",
    "        status_list.append(status)\n",
    "        DecodedDicts.append(decoded_dict)\n",
    "        \n",
    "    return DecodedDicts, strt, log_campaign_list, status_list\n",
    "\n",
    "# Given a structure and voter data and an updated Q, this gives a round-wise campaign allocation requirement to \n",
    "# make the structure feasible. Provides fixed addition to be made in each round, by calling add_campaign.\n",
    "# This function doesn't utilitze the budget to fulfil the structural requirements. Just lists those.\n",
    "def process_campaign_STV_simple(candidates, main, sub, k, Q, ballot_counts, budget, collections):    \n",
    "    \n",
    "    strt, stdt = create_structure(main, sub)\n",
    "    currentdict  = {can: [[can]] for can in candidates}\n",
    "\n",
    "    remaining_candidates = list(stdt.keys())\n",
    "    checked_candidates = []\n",
    "    DecodedDicts = [] # list of how votes look according to given main and sub structure, in each round\n",
    "    status_list = []\n",
    "    log_campaign_list = []\n",
    "\n",
    "    for i in range(len(candidates)-1):\n",
    "        \n",
    "        # # for i'th round, takes the currentdict and updates according to current round of elimination/win\n",
    "        # currentdict = roundupdate(stdt, checked_candidates, remaining_candidates, currentdict)\n",
    "        \n",
    "        # # once the variables are obtained for next round, this converts into numerical data\n",
    "        # decoded_dict = decode_dict(currentdict, candidates, Q, get_new_dict(ballot_counts))\n",
    "        # print(decoded_dict)\n",
    "\n",
    "        ballot_counts_at_time = collections[i][0]\n",
    "\n",
    "        full_decoded_dict = get_new_dict(ballot_counts_at_time)\n",
    "        decoded_dict = {cand: full_decoded_dict.get(cand, 0) for cand in list(stdt.keys())}\n",
    "        #print(decoded_dict)\n",
    "        \n",
    "        # performs the next elimination/win and puts it in the checked_list\n",
    "        t = remaining_candidates.pop(0) \n",
    "        checked_candidates.append(t)\n",
    "        \n",
    "        # checks if the next elimination/win is alright and if not, gives the addition that can make it right\n",
    "        log_campaign_list, status = add_campaign(log_campaign_list, main, remaining_candidates, decoded_dict, Q, k, t, stdt, budget)\n",
    "        if status==False:\n",
    "            return {}, [], [], [False]\n",
    "        status_list.append(status)\n",
    "        DecodedDicts.append(decoded_dict)\n",
    "        \n",
    "    return DecodedDicts, strt, log_campaign_list, status_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This takes the round-wise requirement dict and returns the smart investment.\n",
    "## This may not be very precise. Hence, we loop over this function later to final optimal investment.\n",
    "## The problem arises when we invest in a losing candidate and latter rounds require investment in others to beat this\n",
    "## candidate. Since we don't update log_campaign_dict while running this, we need loops outside the function.\n",
    "\n",
    "def smart_campaign(candidates, log_campaign_list, strt, stdt, Q, DecodedDicts, budget):\n",
    "    \n",
    "    log = deepcopy(log_campaign_list)\n",
    "    dict1 = log[0]  #for later distributing in the first round, where everyone gets what needed\n",
    "    invest_dict = {can: 0 for can in candidates} #investment the candidates have in current rounds.\n",
    "    total_investment_dict = {can: 0 for can in candidates} #total investment until this round\n",
    "    \n",
    "    #old investment in checked candidates, currently available for further dissipation \n",
    "    avl_dict = {can: 0 for can in candidates} \n",
    "    \n",
    "    \n",
    "    for can in dict1.keys(): #first round everyone gets what needed\n",
    "        if dict1[can]>0:\n",
    "            invest_dict[can] = dict1[can]\n",
    "            total_investment_dict[can] = dict1[can]\n",
    "             \n",
    "    t = strt[0][0]      ## the first candidate for elimination or win\n",
    "    decoded_dict = DecodedDicts[0]\n",
    "    \n",
    "    for rd in range(len(log)-1): # next rounds, with possible re-allocation of investment for efficiency \n",
    "        \n",
    "        #first update the log of checked candidates. Dissipate investment into available dict.\n",
    "        if stdt[t] == 1 and invest_dict[t]>0:\n",
    "            dee_invest = deepcopy(invest_dict)\n",
    "            avl_dict[t] = math.floor((decoded_dict[t]+ dee_invest[t]-Q)*(dee_invest[t]/(decoded_dict[t]+dee_invest[t])))\n",
    "            invest_dict[t] = 0\n",
    "            \n",
    "        if stdt[t] == 0 and invest_dict[t]>0:\n",
    "            for rich_can in total_investment_dict.keys():\n",
    "                if rich_can[len(rich_can)-1]==t: #for all investments that are currently owned by t\n",
    "                    avl_dict[rich_can] = deepcopy(total_investment_dict)[rich_can]\n",
    "                \n",
    "            invest_dict[t] = 0\n",
    "        \n",
    "        # Then, process the next checking of candidates.\n",
    "        dict_rd = log[rd+1] #current round requirement \n",
    "        decoded_dict = DecodedDicts[rd+1] #this is needed for the updated votes info\n",
    "        for can in dict_rd.keys():\n",
    "            if dict_rd[can]>invest_dict[can]:\n",
    "                needed_extra =  dict_rd[can] - invest_dict[can]\n",
    "                invest_dict[can] = dict_rd[can] #investment currently the candidate has\n",
    "                for rich_can in avl_dict.keys(): #check if old checked candidates can help\n",
    "                    if avl_dict[rich_can]>0:  \n",
    "                        rich_can_gives = min(avl_dict[rich_can], needed_extra)\n",
    "                        avl_dict[rich_can] = avl_dict[rich_can] - rich_can_gives\n",
    "                        total_investment_dict[rich_can] = total_investment_dict[rich_can]-rich_can_gives\n",
    "                        total_investment_dict[str(rich_can)+str(can)] = rich_can_gives # ballots with >1 choices.\n",
    "                        needed_extra = needed_extra - rich_can_gives\n",
    "                if needed_extra>0:\n",
    "                    total_investment_dict[can] = total_investment_dict[can]+needed_extra\n",
    "        t = strt[rd+1][0]   \n",
    "        amount_spent = sum(total_investment_dict[key] for key in total_investment_dict.keys())   \n",
    "        if amount_spent >budget:\n",
    "            return {}, amount_spent\n",
    "                    \n",
    "    return total_investment_dict, amount_spent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing smart campaign functions to optimize over structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Given main and sub str specifications, this function gives the updated dict and amount that does the job.\n",
    "### Uses the smart campaign function to find optimal investment dict and uses addition to give final dict.\n",
    "### Uses the while loop to repeatedly do the additions, until the given str becomes optimal. \n",
    "\n",
    "def reach_a_structure_check(candidates, main, sub, k, Q_new, ballot_counts, budget):\n",
    "    amount_check = 1\n",
    "    aggre_v_dict = get_new_dict(ballot_counts)\n",
    "    check_aggre_v_dict = deepcopy(aggre_v_dict)\n",
    "    check_ballot_counts = deepcopy(ballot_counts)\n",
    "    #results_list , results_dict, collections = STV_optimal_result_simple(candidates, ballot_counts, k, Q_new)\n",
    "    strt, stdt = create_structure(main, sub)\n",
    "    \n",
    "    while amount_check > 0: #until the additional amount that needs to be spent becomes zero\n",
    "        \n",
    "        DecodedDicts, strt, log_campaign_list, status_list = process_campaign_STV(candidates, main, sub, k, Q_new, check_aggre_v_dict, budget)\n",
    "        #DecodedDicts, strt, log_campaign_list, status_list = process_campaign_STV_simple(candidates, main, sub, k, Q_new, check_ballot_counts, budget, collections)\n",
    "\n",
    "        if all(status_list)==True: # proceed only if campaigning is feasible. \n",
    "            total_investment_dict, amount_check = smart_campaign(candidates, log_campaign_list, strt, stdt, Q_new, DecodedDicts, budget)\n",
    "            #check_aggre_v_dict = campaign_addition_dict(total_investment_dict, candidates, check_aggre_v_dict)\n",
    "            check_ballot_counts = campaign_addition_dict_simple(total_investment_dict, candidates, check_ballot_counts)            \n",
    "            if amount_check>budget:\n",
    "                return False, {}, 0\n",
    "      \n",
    "        else:\n",
    "            return False, {}, 0\n",
    "    #total amount spent in the process  \n",
    "        check_aggre_v_dict = get_new_dict(check_ballot_counts)   \n",
    "    amount_spent = sum(check_aggre_v_dict[candidate] for candidate in candidates) - sum(aggre_v_dict[candidate] for candidate in candidates)\n",
    "    \n",
    "    return amount_spent<budget, check_ballot_counts, amount_spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function uses the 'reach_a_structure_check' function and goes over all sub structures to find the minimum amount\n",
    "### to reach the flipped order. Can be generalized to reach any desired main str. \n",
    "\n",
    "def flip_order_campaign(candidates, k, Q, ballot_counts, budget):\n",
    "    aggre_v_dict = get_new_dict(ballot_counts)\n",
    "    strt_og, stdt_og, collection = STV_optimal_result_simple(candidates, ballot_counts, k, Q)\n",
    "    original_main, original_sub = return_main_sub(strt_og)\n",
    "    Q_new = Q+budget/(k+1)\n",
    "    budget_list_flip= []\n",
    "    campaigned_dict_list = []\n",
    "    for sub in sub_structures(candidates):\n",
    "\n",
    "        status_final, check_aggre_v_dict, amount_spent = reach_a_structure_check(candidates, list(reversed(original_main)), sub, k, Q_new, aggre_v_dict, budget)\n",
    "        \n",
    "        if status_final==True:\n",
    "            \n",
    "            campaigned_dict_list.append(check_aggre_v_dict)\n",
    "            budget_list_flip.append(amount_spent)\n",
    "    \n",
    "    if len(budget_list_flip)==0:\n",
    "        print('increase the budget')\n",
    "        return {}, 0, {}\n",
    "    else:        \n",
    "        min_budget = min(budget_list_flip)\n",
    "        print(budget_list_flip)\n",
    "        min_index=budget_list_flip.index(min_budget)\n",
    "\n",
    "        check_aggre_v_dict =  campaigned_dict_list[min_index]\n",
    "        new_ballot_counts = clean_aggre_dict_diff(check_aggre_v_dict)\n",
    "        \n",
    "        strt_new, stdt_new, collection = STV_optimal_result_simple(candidates, new_ballot_counts, 2, Q_new)\n",
    "        new_main, new_sub = return_main_sub(strt_new)\n",
    "        C = {x: check_aggre_v_dict[x] - aggre_v_dict[x] for x in check_aggre_v_dict if x in aggre_v_dict}\n",
    "        diff = {x:y for x,y in C.items() if y!=0}\n",
    "        \n",
    "        print('New votes to be added = ', clean_aggre_dict_diff(diff))\n",
    "        print('original order = ', original_main, original_sub)\n",
    "        print('new order = ', new_main, new_sub)\n",
    "        print('budget used = ', min_budget)\n",
    "        return check_aggre_v_dict, Q_new, clean_aggre_dict_diff(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function finds minimum additions required for each combination of top k positions, i.e., winners\n",
    "\n",
    "def reach_any_winners_campaign(candidates, k, Q, ballot_counts, budget):\n",
    "    aggre_v_dict = get_new_dict(ballot_counts)\n",
    "    #strt_og, stdt_og = STV_optimal_result(candidates, k, Q, aggre_v_dict)\n",
    "    strt_og, stdt_og, collection = STV_optimal_result_simple(candidates, ballot_counts, k, Q)\n",
    "    original_main, original_sub = return_main_sub(strt_og)\n",
    "    Q_new = Q+budget/(k+1)\n",
    "    \n",
    "    og_winners = give_winners(original_main, k)\n",
    "    strats_frame = {}\n",
    "    strats_frame[''.join(og_winners)] = [0, []]\n",
    "    for comb in combinations(candidates, k):\n",
    "      \n",
    "      if set(comb)!=set(og_winners):  \n",
    "        main_set = str_for_given_winners(comb, candidates)\n",
    "        #strats_frame[''.join(comb)] = [-Q_new, []]\n",
    "    \n",
    "        for current_main in main_set:\n",
    "            budget_list_flip= []\n",
    "            campaigned_dict_list = []\n",
    "            for sub in sub_structures_at_most_k_ones_fixed_last(candidates, k): #sub_structures(candidates)\n",
    "\n",
    "                status_final, check_ballot_counts, amount_spent = reach_a_structure_check(candidates, current_main, sub, k, Q_new, ballot_counts, budget)\n",
    "\n",
    "\n",
    "                if status_final==True:\n",
    "\n",
    "                    campaigned_dict_list.append(check_ballot_counts)\n",
    "                    budget_list_flip.append(amount_spent)\n",
    "\n",
    "            if len(budget_list_flip)>0:       \n",
    "                min_budget = min(budget_list_flip)\n",
    "              \n",
    "                min_index=budget_list_flip.index(min_budget)\n",
    "\n",
    "                check_ballot_counts =  campaigned_dict_list[min_index]\n",
    "                check_aggre_v_dict = get_new_dict(check_ballot_counts)\n",
    "                #strt_new, stdt_new = STV_optimal_result(candidates, k, Q_new, check_aggre_v_dict)\n",
    "                strt_new, stdt_new, collection = STV_optimal_result_simple(candidates, check_ballot_counts, k, Q_new)\n",
    "                new_main, new_sub = return_main_sub(strt_new)\n",
    "                if set(give_winners(new_main, k))!=set(comb):\n",
    "                    print(set(give_winners(new_main, k)),set(comb))\n",
    "                    print(strt_new)\n",
    "                    print('error!')\n",
    "                C = {x: check_aggre_v_dict[x] - aggre_v_dict[x] for x in check_aggre_v_dict if x in aggre_v_dict}\n",
    "                diff = {x:y for x,y in C.items() if y>0}\n",
    "                if strats_frame.get(''.join(comb), [budget, {}])[0] > min_budget:\n",
    "        \n",
    "                    strats_frame[''.join(comb)] = [min_budget, clean_aggre_dict_diff(diff)]\n",
    "           \n",
    "    return {x:y for x,y in strats_frame.items() if y[0]>=0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function finds minimum additions needed to reach any structure. Produces a dict of all reachable orders \n",
    "# within the specified budget.\n",
    "\n",
    "def reach_any_order_campaign(candidates, k, Q, ballot_counts, budget):\n",
    "    aggre_v_dict = get_new_dict(ballot_counts)\n",
    "    strt_og, stdt_og = STV_optimal_result(candidates, k, Q, aggre_v_dict) \n",
    "    #strt_og, stdt_og, collection = STV_optimal_result_simple(candidates, ballot_counts, k, Q)\n",
    "    original_main, original_sub = return_main_sub(strt_og)\n",
    "    Q_new = Q+budget/(k+1)\n",
    "    \n",
    "    og_winners = give_winners(original_main, k)\n",
    "    strats_frame = {}\n",
    "    strats_frame[''.join(og_winners)] = [0, []]\n",
    "    \n",
    "    main_set = main_structures(candidates)\n",
    "    \n",
    "    for current_main in main_set:\n",
    "        budget_list_flip= []\n",
    "        campaigned_dict_list = []\n",
    "        for sub in sub_structures_at_most_k_ones_fixed_last(candidates, k): #sub_structures(candidates)\n",
    "\n",
    "            status_final, check_ballot_counts, amount_spent = reach_a_structure_check(candidates, current_main, sub, k, Q_new, ballot_counts, budget)\n",
    "\n",
    "            if status_final==True:\n",
    "\n",
    "                campaigned_dict_list.append(check_ballot_counts)\n",
    "                budget_list_flip.append(amount_spent)\n",
    "\n",
    "\n",
    "        if len(budget_list_flip)>0:       \n",
    "            min_budget = min(budget_list_flip)\n",
    "        \n",
    "            min_index=budget_list_flip.index(min_budget)\n",
    "\n",
    "            check_ballot_counts =  campaigned_dict_list[min_index]\n",
    "            check_aggre_v_dict = get_new_dict(check_ballot_counts)\n",
    "            strt_new, stdt_new = STV_optimal_result(candidates, k, Q_new, check_aggre_v_dict)\n",
    "            #strt_new, stdt_new, collection = STV_optimal_result_simple(candidates, check_ballot_counts, k, Q_new)\n",
    "            new_main, new_sub = return_main_sub(strt_new)\n",
    "            if current_main != new_main:\n",
    "                print('error')\n",
    "           \n",
    "            C = {x: check_aggre_v_dict[x] - aggre_v_dict[x] for x in check_aggre_v_dict if x in aggre_v_dict}\n",
    "            diff = {x:y for x,y in C.items() if y>0}\n",
    "            if strats_frame.get(''.join(new_main), [budget, {}])[0] > min_budget:\n",
    "\n",
    "                strats_frame[''.join(new_main)] = [min_budget, clean_aggre_dict_diff(diff)]\n",
    "           \n",
    "    return {x:y for x,y in strats_frame.items() if y[0]>=0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removal of candidates under uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To check if we can remove group, and retain candidates\n",
    "\n",
    "def check_removal(candidates, group, ballot_counts, budget):\n",
    "    #strict support check\n",
    "    #group = 'FGHIJKLM'\n",
    "\n",
    "    strict_support = {}\n",
    "\n",
    "    for key, value in ballot_counts.items():\n",
    "        i = 0\n",
    "        newset = []\n",
    "        while key[i] in group:\n",
    "            newset.append(key[i])\n",
    "            i=i+1\n",
    "            if i >= len(key):\n",
    "                break\n",
    "        new_key = ''.join(char for char in newset)\n",
    "        for letter in new_key:\n",
    "            if letter in strict_support:\n",
    "                strict_support[letter] += value\n",
    "            else:\n",
    "                strict_support[letter] = value\n",
    "    can_remove = False\n",
    "   \n",
    "    for best_c_irrelevant in strict_support.keys():\n",
    "\n",
    "        #best_c_irrelevant = max(strict_support, key=strict_support.get)\n",
    "        groupcopy = group\n",
    "\n",
    "        mostly_irrelevant = groupcopy.replace(best_c_irrelevant, \"\")\n",
    "\n",
    "        # Initialize a dictionary for filtered data\n",
    "        filtered_data = {}\n",
    "\n",
    "        # Remove letters maybe_irrelevant {G, H, I, J, K, L}? while retaining the rest of the string\n",
    "        for key, value in ballot_counts.items():\n",
    "            new_key = ''.join(char for char in key if char not in mostly_irrelevant)\n",
    "\n",
    "            filtered_data[new_key] =   filtered_data.get(new_key, 0) + value\n",
    "        filtered_data.pop('', None)\n",
    "\n",
    "        aggre_v_dict = get_new_dict(filtered_data)\n",
    "\n",
    "    \n",
    "        relevant_aggre_dict = {}\n",
    "        #candidates = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "        for c in candidates:\n",
    "            relevant_aggre_dict[c] =  aggre_v_dict[c]\n",
    "\n",
    "        worst_c_relevant = min(relevant_aggre_dict, key=relevant_aggre_dict.get)\n",
    "        #print(int(relevant_aggre_dict[worst_c_relevant]-strict_support[best_c_irrelevant]))\n",
    "        if int(relevant_aggre_dict[worst_c_relevant]-strict_support[best_c_irrelevant])+1>= budget:\n",
    "            can_remove = True\n",
    "        # else:\n",
    "        #     can_remove = False\n",
    "        #     return can_remove\n",
    "        \n",
    "        else: #again check if the addition really changes who drops out after E removal\n",
    "            last_three= sorted(relevant_aggre_dict.items(), key=itemgetter(1))[:3] \n",
    "            #print(last_three, 'last three', group)\n",
    "            #budget not enough to benefit 2 candidates at the bottom\n",
    "            \n",
    "            if 2*last_three[2][1]-last_three[1][1]-last_three[0][1] >budget:\n",
    "                # Remove letters maybe_irrelevant {E, G, H, I, J, K, L}? while retaining the rest of the string\n",
    "\n",
    "                maybe_irrelevant = mostly_irrelevant+ worst_c_relevant\n",
    "                    # Initialize a dictionary for filtered data\n",
    "                filtered_data = {}\n",
    "\n",
    "                for key, value in ballot_counts.items():\n",
    "                    new_key = ''.join(char for char in key if char not in maybe_irrelevant)\n",
    "\n",
    "                    filtered_data[new_key] =   filtered_data.get(new_key, 0) + value\n",
    "                filtered_data.pop('', None)\n",
    "\n",
    "                aggre_v_dict = get_new_dict(filtered_data)\n",
    "\n",
    "                #add budget votes to F\n",
    "                aggre_v_dict[best_c_irrelevant] = aggre_v_dict[best_c_irrelevant]+ budget\n",
    "\n",
    "                # new candidate list that removes E and adds F\n",
    "                relevant_aggre_dict = {}\n",
    "                candidates_temp = candidates.copy()\n",
    "                candidates_temp.remove(worst_c_relevant)\n",
    "                candidates_temp.append(best_c_irrelevant)\n",
    "\n",
    "                for c in candidates_temp:\n",
    "                    relevant_aggre_dict[c] =  aggre_v_dict[c]\n",
    "\n",
    "                new_best_c_irrelevant = min(relevant_aggre_dict, key=relevant_aggre_dict.get)\n",
    "                #print(new_best_c_irrelevant, best_c_irrelevant)\n",
    "\n",
    "\n",
    "                if new_best_c_irrelevant == best_c_irrelevant: #F still gets eliminated\n",
    "                    can_remove = True\n",
    "                    #return True\n",
    "                else:\n",
    "                    #print(new_best_c_irrelevant)\n",
    "                    can_remove = False\n",
    "                    return False\n",
    "            else:\n",
    "                return False\n",
    "    return can_remove\n",
    "\n",
    "def remove_irrelevent( ballot_counts, rt, startcandidates, budget, fullgroup):\n",
    "\n",
    "    candidatesnew = startcandidates\n",
    "    #candidatesnew = candidatesnew[:6]\n",
    "    group = ''.join(char for char in fullgroup if char not in candidatesnew)\n",
    "   \n",
    "    while check_removal(candidatesnew, group, ballot_counts, budget)!=True:\n",
    "\n",
    "        candidatesnew = candidatesnew[:-1]\n",
    "        \n",
    "        #print(candidatesnew)\n",
    "        group = ''.join(char for char in fullgroup if char not in candidatesnew)\n",
    "        if len(candidatesnew)<=2:\n",
    "            stop =False\n",
    "            return candidatesnew, group, stop\n",
    "        \n",
    "\n",
    "    return candidatesnew, group, check_removal(candidatesnew, group, ballot_counts, budget)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_support(ballot_counts, lower_group, upper_group, candidate):\n",
    "\n",
    "    letter_counts ={}\n",
    "    total_cands = lower_group + upper_group\n",
    "    \n",
    "    #strict_support\n",
    "    for key, value in ballot_counts.items():\n",
    "        i = 0\n",
    "        newset = []\n",
    "        if key and key[i] in total_cands:\n",
    "            while key[i] in lower_group and key[i] not in upper_group:\n",
    "                newset.append(key[i])\n",
    "                i=i+1\n",
    "                if i >= len(key):\n",
    "                    break\n",
    "\n",
    "        new_key = ''.join(char for char in newset)\n",
    "        if candidate in new_key:\n",
    "            if candidate in letter_counts:\n",
    "                letter_counts[candidate] += value\n",
    "            else:\n",
    "                letter_counts[candidate] = value\n",
    "\n",
    "    return letter_counts.get(candidate, 0)\n",
    "\n",
    "\n",
    "def predict_wins(ballot_counts, candidates, k, Q, budget):\n",
    "    C_W = []\n",
    "    for cand in candidates:\n",
    "        if budget + strict_support(ballot_counts,  candidates, [], cand)> Q+budget/(k+1):\n",
    "            C_W.append(cand)\n",
    "\n",
    "    C_bar_W = [cand for cand in candidates if cand not in C_W]\n",
    "    number_unique_ballots = 0\n",
    "    for cand in C_W:\n",
    "        # Call strict_support only for new unique ballots\n",
    "        c_new = C_bar_W +[cand]\n",
    "        support_count = strict_support(ballot_counts, c_new, [], cand)\n",
    "        \n",
    "        number_unique_ballots += support_count  # Accumulate only unique contribution\n",
    "\n",
    "\n",
    "    U_W = min (k, int(budget + number_unique_ballots)/(Q+budget/(k+1)))\n",
    "    #print((budget + number_unique_ballots)/(Q+budget/(k+1)), number_unique_ballots)\n",
    "    return U_W\n",
    "\n",
    "def predict_losses(ballot_counts, candidates, k , Q, budget):\n",
    "    aggre_v_dict = get_new_dict(ballot_counts)\n",
    "    first_choice_votes = [aggre_v_dict[i] for i in candidates]\n",
    "    first_choice_votes=sorted(first_choice_votes, reverse=True)\n",
    "    # print(first_choice_votes)\n",
    "\n",
    "    C_L =[]\n",
    "    for cand in candidates:\n",
    "        if budget + strict_support(ballot_counts,  candidates, [], cand) <= first_choice_votes[k-1]:\n",
    "            C_L.append(cand)\n",
    "    # print(C_L)\n",
    "\n",
    "    T = []\n",
    "    for c_i in C_L:\n",
    "\n",
    "        t_i = 0\n",
    "        for ballot, count in ballot_counts.items():\n",
    "            # Check if this ballot starts with c_i\n",
    "            if len(ballot) > 0 and ballot[0] == c_i:\n",
    "                # Look at subsequent candidates in the ballot\n",
    "                for cand in ballot[1:]:\n",
    "                    if cand not in C_L:\n",
    "                        t_i += count  # Found a candidate outside C_L -> add once\n",
    "                        break         # Don't check further; we already transferred\n",
    "        T.append(t_i)\n",
    "    T= sorted(T,reverse=True)\n",
    "    \n",
    "    i_L = 1\n",
    "    if len(T)==0:\n",
    "        return 0\n",
    "    \n",
    "    while sum(T[:i_L]) + first_choice_votes[0] < Q+budget/(k+1):\n",
    "        i_L = i_L+1\n",
    "        if i_L>=len(T):\n",
    "            return i_L\n",
    "\n",
    "    return i_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elections experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The poll data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from candidate names to variables\n",
    "candidates_mapping = {\n",
    "    \"Trump\": \"A\",\n",
    "    \"Haley\": \"B\",\n",
    "    \"Ramaswamy\": \"C\",\n",
    "    \"DeSantis\": \"D\",\n",
    "    \"Christie\":\"E\",\n",
    "    \"Pence\": \"F\",\n",
    "    \"Scott\": \"G\",\n",
    "    \"Hurd\": \"H\",\n",
    "    \"Hutchinson\": \"I\",\n",
    "    \"Youngkin\": \"J\",\n",
    "    \"Burgum\": \"K\",\n",
    "    \"Elder\": \"L\",\n",
    "    \"Suarez\": \"M\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801.000046\n"
     ]
    }
   ],
   "source": [
    "## Case studies: republican primary\n",
    "\n",
    "df = pd.read_csv(\"poll_data.csv\")\n",
    "df = df.drop(columns = ['record', 'QBASE'])\n",
    "df.head()\n",
    "\n",
    "\n",
    "# Initialize a dictionary to store the counts of each ballot type as strings\n",
    "ballot_counts = {}\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df.iterrows():\n",
    "    # Initialize an empty list to store valid candidates\n",
    "    valid_candidates = []\n",
    "    \n",
    "    # Iterate through columns rank1 to rank5\n",
    "    for i in range(1, 14):\n",
    "        candidate = row[f'rank{i}']\n",
    "        valid_candidates.append(candidates_mapping[candidate])\n",
    "    \n",
    "\n",
    "    ballot_type = ''.join(valid_candidates)\n",
    "\n",
    "    # Use the 'weight' column to determine the number of voters for this ballot type\n",
    "    weight = row['weight']\n",
    "\n",
    "    # Add the weight to the count for this ballot type in the dictionary\n",
    "    if ballot_type not in ballot_counts:\n",
    "        ballot_counts[ballot_type] = weight\n",
    "    else:\n",
    "        ballot_counts[ballot_type] += weight\n",
    "\n",
    "print(sum(ballot_counts.values()))\n",
    "#ballot_counts['E'] = 30\n",
    "# ballot_counts['D'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary for filtered data\n",
    "filtered_data = {}\n",
    "\n",
    "# Remove letters {G, H, I, J, K, L} while retaining the rest of the string\n",
    "for key, value in ballot_counts.items():\n",
    "    new_key = ''.join(char for char in key if char not in 'FGHIJKLM')\n",
    "    \n",
    "    filtered_data[new_key] =   filtered_data.get(new_key, 0) + value\n",
    "filtered_data.pop('', None)\n",
    "print(len(filtered_data))\n",
    "# aggre_v_dict = get_new_dict(filtered_data)\n",
    "# candidates = ['A', 'B', 'C', 'D']\n",
    "# for c in candidates:\n",
    "#     print(c, aggre_v_dict[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 387.9737379999999\n",
      "B 95.082114\n",
      "C 118.92247600000002\n",
      "D 112.76345800000001\n",
      "E 86.25825999999999\n",
      "801.5\n",
      "{'B': 82.14700099999996, 'K': 15.527009, 'G': 42.271861, 'I': 20.949628999999998, 'L': 8.297495, 'H': 17.005557, 'J': 15.029082, 'M': 10.800882}\n"
     ]
    }
   ],
   "source": [
    "candidates = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']\n",
    "candidates = ['A', 'B', 'C', 'D', 'E']#, 'C', 'D', 'E', 'F', 'G']\n",
    "#filtered_data  = ballot_counts\n",
    "#aggre_v_dict = get_new_dict(ballot_counts)\n",
    "aggre_v_dict = get_new_dict(filtered_data)\n",
    "#print(aggre_v_dict)\n",
    "for c in candidates:\n",
    "    print(c, aggre_v_dict[c])\n",
    "\n",
    "#print(aggre_v_dict)\n",
    "k=1\n",
    "Q = round(sum(aggre_v_dict[candidate] for candidate in candidates)/(k+1)+1,3)+400\n",
    "print(Q)\n",
    "\n",
    "#strict support check\n",
    "group = 'BGHIJKLM'\n",
    "\n",
    "letter_counts = {}\n",
    "\n",
    "#strict_support\n",
    "for key, value in ballot_counts.items():\n",
    "    i = 0\n",
    "    newset = []\n",
    "    while key[i] in group:\n",
    "        newset.append(key[i])\n",
    "        i=i+1\n",
    "    new_key = ''.join(char for char in newset)\n",
    "    for letter in new_key:\n",
    "        if letter in letter_counts:\n",
    "            letter_counts[letter] += value\n",
    "        else:\n",
    "            letter_counts[letter] = value\n",
    "\n",
    "print(letter_counts)\n",
    "\n",
    "\n",
    "best_c_irrelevant = max(letter_counts, key=letter_counts.get)\n",
    "\n",
    "\n",
    "#if int(aggre_v_dict['E']-letter_counts[best_c_irrelevant])>=40:\n",
    "#    print('delete them')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9338884754858259\n",
      "8.466721689587757\n",
      "10.160136586413405\n"
     ]
    }
   ],
   "source": [
    "for c in ['EA','EC', 'ED']:\n",
    "    #print(c, aggre_v_dict[c]/aggre_v_dict['E']*8.84)\n",
    "    #print(c, aggre_v_dict[c]/aggre_v_dict['E']*8.84)\n",
    "    aggre_v_dict[c] = aggre_v_dict[c]+aggre_v_dict[c]/aggre_v_dict['E']*8.84\n",
    "    print(aggre_v_dict[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggre_v_dict['E'] = aggre_v_dict['E']+ 2\n",
    "\n",
    "rt, dt = STV_optimal_result(candidates, k, Q, aggre_v_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['E', 0], ['D', 0], ['C', 0], ['B', 0], ['A', 0]] {'E': 0, 'D': 0, 'C': 0, 'B': 0, 'A': 0}\n"
     ]
    }
   ],
   "source": [
    "print(rt, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time =  0.3700571060180664\n",
      "{'AB': [0, []], 'ABCDE': [0.0, {}], 'ABDCE': [6.0, {'D': 6.0}], 'ACBDE': [33.0, {'C': 33.0}], 'ACDEB': [11.0, {'E': 8.0, 'D': 3.0}], 'ACEDB': [8.0, {'E': 8.0}], 'ADCEB': [26.0, {'D': 18.0, 'ED': 8.0}], 'ADECB': [21.0, {'E': 14.0, 'D': 7.0}], 'AEDCB': [35.0, {'E': 28.0, 'D': 7.0}]}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#strats_frame = reach_any_winners_campaign(candidates, 2, Q, aggre_v_dict, 300)\n",
    "strats_frame = reach_any_order_campaign(candidates, 2, Q, aggre_v_dict, 40)\n",
    "end = time.time()\n",
    "print('total time = ' , end - start)\n",
    "print( strats_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AB': [0, []], 'AC': [8.0, {'E': 8.0}], 'AD': [21.0, {'E': 14.0, 'D': 7.0}], 'AE': [35.0, {'E': 28.0, 'D': 7.0}]}\n"
     ]
    }
   ],
   "source": [
    "strats_frame2 = reach_any_winners_campaign(candidates, 2, Q, aggre_v_dict, 40)\n",
    "print( strats_frame2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portland Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### District 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42686\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from candidate names to variables\n",
    "candidates_mapping = {\n",
    "    \"Candace Avalos\": \"A\",\n",
    "    \"Jamie Dunphy\": \"B\",\n",
    "    \"Loretta Smith\": \"C\",\n",
    "    \"Noah Ernst\": \"E\",\n",
    "    \"Terrence Hayes\":\"D\",\n",
    "    \"Steph Routh\": \"F\",\n",
    "    \"Timur Ender\": \"G\",\n",
    "    \"Doug Clove\": \"H\",\n",
    "    \"Peggy Sue Owens\": \"I\",\n",
    "    \"David Linn\": \"J\",\n",
    "    \"Joe Allen\": \"K\",\n",
    "    \"Michael (Mike) Sands\": \"L\",\n",
    "    \"Deian Salazar\": \"M\",\n",
    "    \"Cayle Tern\": \"N\",\n",
    "    \"Thomas Shervey\": \"O\",\n",
    "    \"Joe Furi\": \"P\"\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"/Users/saeesbox/Desktop/dis1.csv\")\n",
    "df = df.drop(columns = ['RowNumber'])\n",
    "df.head()\n",
    "\n",
    "# Initialize a dictionary to store the counts of each ballot type as strings\n",
    "ballot_counts = {}\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df.iterrows():\n",
    "    # Initialize an empty list to store valid candidates\n",
    "    valid_candidates = []\n",
    "    \n",
    "    # Iterate through columns rank1 to rank5\n",
    "    for i in range(1, 7):\n",
    "        candidate = row[f'Choice_{i}']\n",
    "        if candidate in candidates_mapping.keys():\n",
    "            valid_candidates.append(candidates_mapping[candidate])\n",
    "    \n",
    "\n",
    "    # Check if the ballot is empty (no valid candidates)\n",
    "    if valid_candidates:  # Skip empty ballots\n",
    "        \n",
    "        ballot_type = ''.join(valid_candidates)\n",
    "\n",
    "        # Add the weight to the count for this ballot type in the dictionary\n",
    "        if ballot_type not in ballot_counts:\n",
    "            ballot_counts[ballot_type] = 1\n",
    "        else:\n",
    "            ballot_counts[ballot_type] += 1\n",
    "\n",
    "print(sum(ballot_counts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39880\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary for filtered data\n",
    "filtered_data = {}\n",
    "\n",
    "# Remove letters {G, H, I, J, K, L} while retaining the rest of the string\n",
    "for key, value in ballot_counts.items():\n",
    "    new_key = ''.join(char for char in key if char not in 'GDIJKLMNOP')\n",
    "    \n",
    "    filtered_data[new_key] =   filtered_data.get(new_key, 0) + value\n",
    "filtered_data.pop('', None)\n",
    "print(sum(filtered_data.values()))\n",
    "# aggre_v_dict = get_new_dict(filtered_data)\n",
    "# candidates = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "# for c in candidates:\n",
    "#     print(c, aggre_v_dict[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 10991\n",
      "B 6314\n",
      "C 7889\n",
      "E 6397\n",
      "F 5439\n",
      "H 2850\n",
      "10672.5\n",
      "{'D': 4845, 'L': 1650, 'G': 4469, 'J': 1960, 'M': 1197, 'K': 1603, 'P': 857, 'O': 857, 'I': 1630, 'N': 1371}\n",
      "D\n",
      "[['P', 0], ['O', 0], ['N', 0], ['M', 0], ['L', 0], ['K', 0], ['I', 0], ['J', 0], ['H', 0], ['G', 0], ['F', 0], ['A', 1], ['E', 0], ['D', 0], ['C', 1], ['B', 0]] {'A': 1, 'B': 0, 'C': 1, 'E': 0, 'D': 0, 'F': 0, 'G': 0, 'H': 0, 'I': 0, 'J': 0, 'K': 0, 'L': 0, 'M': 0, 'N': 0, 'O': 0, 'P': 0}\n",
      "['A', 'C', 'B', 'D', 'E', 'F', 'G', 'H', 'J', 'I', 'K', 'L', 'M', 'N', 'O', 'P']\n"
     ]
    }
   ],
   "source": [
    "candidates = ['A', 'B', 'C','E', 'F', 'H'] #, 'C', 'D', 'E', 'F', 'G']\n",
    "#candidates = ['A', 'B', 'C', 'D', 'E', 'F','G','H','I','J','K','L','M','N','O','P']\n",
    "#filtered_data  = ballot_counts\n",
    "full_aggre_v_dict = get_new_dict(ballot_counts)\n",
    "aggre_v_dict = get_new_dict(filtered_data)\n",
    "#print(aggre_v_dict)\n",
    "for c in candidates:\n",
    "    print(c, aggre_v_dict[c])                                                                           \n",
    "\n",
    "#print(aggre_v_dict)\n",
    "k=3\n",
    "Q = round(sum(full_aggre_v_dict[candidate] for candidate in candidates_mapping.values())/(k+1)+1,3)\n",
    "print(Q)\n",
    "\n",
    "#strict support check\n",
    "group = 'GDIJKLMNOP'\n",
    "\n",
    "letter_counts = {}\n",
    "\n",
    "#strict_support\n",
    "for key, value in ballot_counts.items():\n",
    "    i = 0\n",
    "    newset = []\n",
    "    if key and key[i] in candidates_mapping.values():\n",
    "        while key[i] in group:\n",
    "            newset.append(key[i])\n",
    "            i=i+1\n",
    "            if i >= len(key):\n",
    "                break\n",
    "\n",
    "    new_key = ''.join(char for char in newset)\n",
    "    for letter in new_key:\n",
    "        if letter in letter_counts:\n",
    "            letter_counts[letter] += value\n",
    "        else:\n",
    "            letter_counts[letter] = value\n",
    "\n",
    "print(letter_counts)\n",
    "\n",
    "\n",
    "best_c_irrelevant = max(letter_counts, key=letter_counts.get)\n",
    "print(best_c_irrelevant)\n",
    "#ballot_counts['A'] = ballot_counts['A']+10\n",
    "\n",
    "\n",
    "rt, dt, collection = STV_optimal_result_simple(list(candidates_mapping.values()), ballot_counts, 3, Q)\n",
    "print(rt,dt)\n",
    "results, subresults = return_main_sub(rt)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#predict_wins(filtered_data, candidates, Q, budget)\n",
    "\n",
    "#candidates = ['A', 'B', 'C', 'D', 'E', 'F','G','H','I','J','K','L','M','N','O','P']\n",
    "#predict_losses(filtered_data, candidates, k , Q, 42686*0.05)\n",
    "predict_losses(ballot_counts, list(candidates_mapping.values()), k , Q, 42686*0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time =  783.0910172462463\n",
      "{'ACB': [0, []], 'ACD': [695, {'D': 695}], 'ACE': [1214, {'E': 1214}], 'ACF': [816, {'F': 816}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "budget = 42686*0.045 #= 1920\n",
    "#Q = round((budget+sum(full_aggre_v_dict[candidate] for candidate in candidates_mapping.values()))/(k+1)+1,3)\n",
    "strats_frame = reach_any_winners_campaign(candidates, 3, Q, filtered_data, budget)\n",
    "#strats_frame = reach_any_order_campaign(candidates, 3, Q, filtered_data, budget)\n",
    "end = time.time()\n",
    "print('total time = ' , end - start)\n",
    "print( strats_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n"
     ]
    }
   ],
   "source": [
    "print(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'C'] BDEFGHIJKLMNOP False\n"
     ]
    }
   ],
   "source": [
    "#check_removal(candidates, 'HIJKLMNOP', ballot_counts, 43396*0.05)\n",
    "#remove_irrelevent( ballot_counts, cands_dontwant, startcandidates, 43396*0.05, fullgroup, stop)\n",
    "\n",
    "candidates_reduced, group_remaining, stop = remove_irrelevent( ballot_counts, rt, \n",
    "                results[:7],42686*0.045 , 'ABCDEFGHIJKLMNOP')\n",
    "\n",
    "print(candidates_reduced, group_remaining, stop)\n",
    "\n",
    "# total time =  535.8463587760925\n",
    "# 2000\n",
    "# {'ACB': [0, []], 'ACBDEFG': [384, {'E': 165, 'F': 219}], 'ACBDEGF': [8, {'E': 8}], 'ACBDFEG': [219, {'F': 219}], 'ACBDFGE': [452, {'G': 117, 'F': 335}], 'ACBDGEF': [0, {}], 'ACBDGFE': [665, {'G': 330, 'F': 335}], 'ACBEDFG': [384, {'E': 165, 'FE': 219}], 'ACBEDGF': [317, {'E': 312, 'A': 5}], 'ACBEGDF': [347, {'E': 177, 'G': 170}], 'ACBGDEF': [894, {'G': 894}], 'ACBGDFE': [894, {'G': 559, 'FG': 335}], 'ACEBDGF': [736, {'E': 731, 'A': 5}], 'ACEBGDF': [736, {'E': 561, 'A': 5, 'GE': 170}], 'ACFDBEG': [765, {'F': 765}], 'ACFDBGE': [695, {'F': 578, 'GF': 117}], 'AFCDBEG': [934, {'F': 934}], 'AFCDBGE': [806, {'F': 689, 'GF': 117}]}\n",
    "#{'ACB': [0, []], 'ABD': [1986, {'D': 926, 'B': 492, 'FD': 568}], 'ACD': [669, {'D': 669}], 'ACE': [1180, {'E': 1180}], 'ACF': [833, {'F': 833}], 'ACG': [1808, {'G': 1808}]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### District 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77036\n",
      "299\n",
      "A 17418\n",
      "B 17155\n",
      "C 17136\n",
      "D 12228\n",
      "G 6861\n",
      "19260.0\n",
      "{'O': 2614, 'T': 1369, 'I': 4232, 'R': 1599, 'E': 8576, 'N': 2399, 'F': 8217, 'L': 3260, 'S': 1621, 'J': 4528, 'H': 5433, 'U': 1033, 'K': 3499, 'M': 2480, 'P': 1669, 'Q': 1777, 'V': 569}\n",
      "E\n",
      "[['V', 0], ['U', 0], ['T', 0], ['S', 0], ['R', 0], ['Q', 0], ['P', 0], ['O', 0], ['N', 0], ['M', 0], ['L', 0], ['K', 0], ['J', 0], ['I', 0], ['H', 0], ['G', 0], ['E', 0], ['F', 0], ['A', 1], ['D', 0], ['B', 1], ['C', 1]] {'A': 1, 'B': 1, 'C': 1, 'D': 0, 'E': 0, 'F': 0, 'G': 0, 'H': 0, 'I': 0, 'J': 0, 'K': 0, 'L': 0, 'M': 0, 'N': 0, 'O': 0, 'P': 0, 'Q': 0, 'R': 0, 'S': 0, 'T': 0, 'U': 0, 'V': 0}\n"
     ]
    }
   ],
   "source": [
    "candidates_mapping = {\n",
    "    \"Sameer Kanal\": \"A\",\n",
    "    \"Dan Ryan\": \"B\",\n",
    "    \"Elana Pirtle-Guiney\": \"C\",\n",
    "    \"Tiffani Penson\": \"D\",\n",
    "    \"Michelle DePass\": \"E\",\n",
    "    \"Nat West\": \"F\",\n",
    "    \"Marnie Glickman\": \"G\",\n",
    "    \"Jonathan Tasini\": \"H\",\n",
    "    \"Bob Simril\": \"I\",\n",
    "    \"Mariah Hudson\": \"J\",\n",
    "    \"Michael (Mike) Marshall\": \"K\",\n",
    "    \"James Armstrong\": \"L\",\n",
    "    \"Chris Olson\": \"M\",\n",
    "    \"Debbie Kitchin\": \"N\",\n",
    "    \"Jennifer Park\": \"O\",\n",
    "    \"Nabil Zaghloul\": \"P\",\n",
    "    \"Will Mespelt\": \"Q\",\n",
    "    \"Laura Streib\": \"R\",\n",
    "    \"Reuben Berlin\": \"S\",\n",
    "    \"Liz Taylor\": \"T\",\n",
    "    \"Sam Sachs\": \"U\",\n",
    "    \"Antonio Jamal PettyJohnBlue\": \"V\"\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"/Users/saeesbox/Desktop/dis2.csv\")\n",
    "df = df.drop(columns = ['RowNumber'])\n",
    "df.head()\n",
    "\n",
    "# Initialize a dictionary to store the counts of each ballot type as strings\n",
    "ballot_counts = {}\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df.iterrows():\n",
    "    # Initialize an empty list to store valid candidates\n",
    "    valid_candidates = []\n",
    "    \n",
    "    # Iterate through columns rank1 to rank5\n",
    "    for i in range(1, 7):\n",
    "        candidate = row[f'Choice_{i}']\n",
    "        if candidate in candidates_mapping.keys():\n",
    "            valid_candidates.append(candidates_mapping[candidate])\n",
    "    \n",
    "\n",
    "    # Check if the ballot is empty (no valid candidates)\n",
    "    if valid_candidates:  # Skip empty ballots\n",
    "        \n",
    "        ballot_type = ''.join(valid_candidates)\n",
    "\n",
    "        # Add the weight to the count for this ballot type in the dictionary\n",
    "        if ballot_type not in ballot_counts:\n",
    "            ballot_counts[ballot_type] = 1\n",
    "        else:\n",
    "            ballot_counts[ballot_type] += 1\n",
    "\n",
    "print(sum(ballot_counts.values()))\n",
    "\n",
    "# Initialize a dictionary for filtered data\n",
    "filtered_data = {}\n",
    "\n",
    "# Remove letters {G, H, I, J, K, L} while retaining the rest of the string\n",
    "for key, value in ballot_counts.items():\n",
    "    new_key = ''.join(char for char in key if char not in 'FEHIJKLMNOPQRSTUV')\n",
    "    \n",
    "    filtered_data[new_key] =   filtered_data.get(new_key, 0) + value\n",
    "filtered_data.pop('', None)\n",
    "print(len(filtered_data))\n",
    "# aggre_v_dict = get_new_dict(filtered_data)\n",
    "# candidates = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "# for c in candidates:\n",
    "#     print(c, aggre_v_dict[c])\n",
    "\n",
    "candidates = ['A', 'B', 'C', 'D',  'G']#, 'E', 'F', 'G']#, 'C', 'D', 'E', 'F', 'G']\n",
    "#filtered_data  = ballot_counts\n",
    "full_aggre_v_dict = get_new_dict(ballot_counts)\n",
    "aggre_v_dict = get_new_dict(filtered_data)\n",
    "#print(aggre_v_dict)\n",
    "for c in candidates:\n",
    "    print(c, aggre_v_dict[c])                                                                           \n",
    "\n",
    "#print(aggre_v_dict)\n",
    "k=3\n",
    "Q = round(sum(full_aggre_v_dict[candidate] for candidate in list(candidates_mapping.values()))/(k+1)+1,3)\n",
    "print(Q)\n",
    "\n",
    "#strict support check\n",
    "group = 'FEHIJKLMNOPQRSTUV'\n",
    "\n",
    "letter_counts = {}\n",
    "\n",
    "#strict_support\n",
    "for key, value in ballot_counts.items():\n",
    "    i = 0\n",
    "    newset = []\n",
    "    if key and key[i] in candidates_mapping.values():\n",
    "        while key[i] in group:\n",
    "            newset.append(key[i])\n",
    "            i=i+1\n",
    "            if i >= len(key):\n",
    "                break\n",
    "\n",
    "    new_key = ''.join(char for char in newset)\n",
    "    for letter in new_key:\n",
    "        if letter in letter_counts:\n",
    "            letter_counts[letter] += value\n",
    "        else:\n",
    "            letter_counts[letter] = value\n",
    "\n",
    "print(letter_counts)\n",
    "\n",
    "\n",
    "best_c_irrelevant = max(letter_counts, key=letter_counts.get)\n",
    "print(best_c_irrelevant)\n",
    "\n",
    "rt, dt, collection = STV_optimal_result_simple(list(candidates_mapping.values()), ballot_counts, 3, Q)\n",
    "print(rt,dt)\n",
    "results, subresults = return_main_sub(rt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#predict_wins(filtered_data, candidates, k, Q, budget)\n",
    "budget = 77036*0.05 #= 3851.8\n",
    "#ans = predict_losses(ballot_counts, list(candidates_mapping.values()), k , Q, budget)\n",
    "ans = predict_losses(filtered_data, candidates, k, Q, budget)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5007.34\n",
      "total time =  0.7622010707855225\n",
      "{'ABC': [0, []], 'ACD': [4390, {'D': 4390}]}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "budget = 77036*0.065 # = 3081.44  \n",
    "print(budget)\n",
    "strats_frame = reach_any_winners_campaign(candidates, 3, Q, filtered_data, budget) \n",
    "#strats_frame = reach_any_order_campaign(candidates, 3, Q, filtered_data, budget)\n",
    "end = time.time()\n",
    "print('total time = ' , end - start)\n",
    "print( strats_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D'] EFGHIJKLMNOPQRSTUV True\n"
     ]
    }
   ],
   "source": [
    "candidates_reduced, group_remaining, stop = remove_irrelevent( ballot_counts, ['A', 'B', 'C', 'D', 'E', 'F', 'G'], \n",
    "                results[:15], 77036*0.065 , 'ABCDEFGHIJKLMNOPQRSTUV')\n",
    "\n",
    "print(candidates_reduced, group_remaining, stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F 9232\n",
      "A 17542\n",
      "D 11829\n",
      "B 16488\n",
      "C 16664\n",
      "FADBC ['A', 'B', 'C', 'D', 'F']\n",
      "['A', 'B', 'C', 'D'] F True\n"
     ]
    }
   ],
   "source": [
    "small_election_number = 17 #start after -- rounds are complete\n",
    "\n",
    "group = ''.join(char for char in [rt[i][0] for i in range(small_election_number, len(rt))])\n",
    "ballot_counts_short = collection[small_election_number][0]\n",
    "test = [rt[i][0] for i in range(small_election_number, len(rt))]\n",
    "ordered_test = sorted(test, key=lambda x: results.index(x))\n",
    "fil_data = get_new_dict(ballot_counts_short)\n",
    "for c in group:\n",
    "    print(c, fil_data[c])\n",
    "print(group, ordered_test)\n",
    "\n",
    "candidates_reduced, group_remaining, stop = remove_irrelevent(ballot_counts_short, ['A', 'B', 'C', 'D', 'E', 'F', 'G'], \n",
    "                ordered_test,77036*0.065 , group)\n",
    "\n",
    "print(candidates_reduced, group_remaining, stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### District 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84353\n",
      "A 27873\n",
      "B 20541\n",
      "C 20528\n",
      "E 6957\n",
      "21089.25\n",
      "{'b': 503, 'T': 1900, 'G': 5530, 'W': 724, 'V': 801, 'U': 1604, 'L': 3219, 'S': 1415, 'Y': 692, 'd': 387, 'P': 1584, 'F': 6064, 'D': 9057, 'K': 3041, 'N': 2925, 'J': 4127, 'R': 1405, 'O': 2035, 'I': 3013, 'Z': 458, 'H': 4236, 'c': 1000, 'Q': 1467, 'M': 2439, 'X': 827, 'a': 661}\n",
      "D\n",
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'H', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'Q', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'a', 'Z', 'b', 'c', 'd']\n"
     ]
    }
   ],
   "source": [
    "candidates_mapping = {\n",
    "    \"Steve Novick\": \"A\",\n",
    "    \"Angelita Morillo\": \"B\",\n",
    "    \"Tiffany Koyama Lane\": \"C\",\n",
    "    \"Kezia Wanner\": \"D\",\n",
    "    \"Rex Burkholder\": \"E\",\n",
    "    \"Jesse Cornett\": \"F\",\n",
    "    \"Harrison Kass\": \"G\",\n",
    "    \"Daniel DeMelo\": \"H\",\n",
    "    \"Philippe Knab\": \"I\",\n",
    "    \"Sandeep Bali\": \"J\",\n",
    "    \"Cristal Azul Otero\": \"K\",\n",
    "    \"Jonathan (Jon) Walker\": \"L\",\n",
    "    \"Chris Flanary\": \"M\",\n",
    "    \"Melodie Beirwagen\": \"N\",\n",
    "    \"Matthew (Matt) Anderson\": \"O\",\n",
    "    \"Ahlam K Osman\": \"P\",\n",
    "    \"Luke Zak\": \"Q\",\n",
    "    \"Heart Free Pham\": \"R\",\n",
    "    \"Brian Conley\": \"S\",\n",
    "    \"Terry Parker\": \"T\",\n",
    "    \"Dan Gilk\": \"U\",\n",
    "    \"Christopher Brummer\": \"V\",\n",
    "    \"John Sweeney\": \"W\",\n",
    "    \"Kelly Janes (KJ)\": \"X\",\n",
    "    \"Theo Hathaway Saner\": \"Y\",\n",
    "    \"Jaclyn Smith-Moore\": \"Z\",\n",
    "    \"Patrick Hilton\": \"a\",\n",
    "    \"David O'Connor\": \"b\",\n",
    "    \"Kenneth (Kent) R Landgraver III\": \"c\",\n",
    "    \"Clifford Higgins\": \"d\"\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/Users/saeesbox/Desktop/dis3.csv\")\n",
    "df = df.drop(columns = ['RowNumber'])\n",
    "df.head()\n",
    "\n",
    "# Initialize a dictionary to store the counts of each ballot type as strings\n",
    "ballot_counts = {}\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df.iterrows():\n",
    "    # Initialize an empty list to store valid candidates\n",
    "    valid_candidates = []\n",
    "    \n",
    "    # Iterate through columns rank1 to rank5\n",
    "    for i in range(1, 7):\n",
    "        candidate = row[f'Choice_{i}']\n",
    "        if candidate in candidates_mapping.keys():\n",
    "            valid_candidates.append(candidates_mapping[candidate])\n",
    "\n",
    "    # Check if the ballot is empty (no valid candidates)\n",
    "    if valid_candidates:  # Skip empty ballots\n",
    "        \n",
    "        ballot_type = ''.join(valid_candidates)\n",
    "\n",
    "        # Add the weight to the count for this ballot type in the dictionary\n",
    "        if ballot_type not in ballot_counts:\n",
    "            ballot_counts[ballot_type] = 1\n",
    "        else:\n",
    "            ballot_counts[ballot_type] += 1\n",
    "\n",
    "print(sum(ballot_counts.values()))\n",
    "\n",
    "# Initialize a dictionary for filtered data\n",
    "filtered_data = {}\n",
    "\n",
    "# Remove letters {G, H, I, J, K, L} while retaining the rest of the string\n",
    "for key, value in ballot_counts.items():\n",
    "    new_key = ''.join(char for char in key if char not in 'DFGHIJKLMNOPQRSTUVWXYZabcd')\n",
    "    \n",
    "    filtered_data[new_key] =   filtered_data.get(new_key, 0) + value\n",
    "filtered_data.pop('', None)\n",
    "\n",
    "# aggre_v_dict = get_new_dict(filtered_data)\n",
    "# candidates = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "# for c in candidates:\n",
    "#     print(c, aggre_v_dict[c])\n",
    "\n",
    "candidates = ['A', 'B', 'C', 'E']#, 'G']#, 'C', 'D', 'E', 'F', 'G']\n",
    "#filtered_data  = ballot_counts\n",
    "full_aggre_v_dict = get_new_dict(ballot_counts)\n",
    "aggre_v_dict = get_new_dict(filtered_data)\n",
    "#print(aggre_v_dict)\n",
    "for c in candidates:\n",
    "    print(c, aggre_v_dict[c])                                                                           \n",
    "\n",
    "#print(aggre_v_dict)\n",
    "k=3\n",
    "Q = round(sum(full_aggre_v_dict[candidate] for candidate in list(candidates_mapping.values()))/(k+1)+1,3)\n",
    "print(Q)\n",
    "\n",
    "#strict support check\n",
    "group = 'DFGHIJKLMNOPQRSTUVWXYZabcd'\n",
    "\n",
    "letter_counts = {}\n",
    "\n",
    "#strict_support\n",
    "for key, value in ballot_counts.items():\n",
    "    i = 0\n",
    "    newset = []\n",
    "    if key and key[i] in candidates_mapping.values():\n",
    "        while key[i] in group:\n",
    "            newset.append(key[i])\n",
    "            i=i+1\n",
    "            if i >= len(key):\n",
    "                break\n",
    "\n",
    "    new_key = ''.join(char for char in newset)\n",
    "    for letter in new_key:\n",
    "        if letter in letter_counts:\n",
    "            letter_counts[letter] += value\n",
    "        else:\n",
    "            letter_counts[letter] = value\n",
    "\n",
    "print(letter_counts)\n",
    "\n",
    "best_c_irrelevant = max(letter_counts, key=letter_counts.get)\n",
    "print(best_c_irrelevant)\n",
    "\n",
    "rt, dt, collection = STV_optimal_result_simple(list(candidates_mapping.values()), ballot_counts, 3, Q)\n",
    "\n",
    "results, subresults= return_main_sub(rt)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.36\n"
     ]
    }
   ],
   "source": [
    "\n",
    "surplusA = {}\n",
    "A_original = get_new_dict(ballot_counts)['A']\n",
    "A_needs = Q - A_original\n",
    "for cand in 'DEFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "    fil_data = {}\n",
    "    for key, value in ballot_counts.items():\n",
    "    \n",
    "        new_key = ''.join(char for char in key if char not in 'DEFGHIJKLMNOPQRSTUVWXYZabcd'.replace(cand, \"\"))\n",
    "        \n",
    "        fil_data[new_key] =   fil_data.get(new_key, 0) + value\n",
    "    fil_data.pop('', None)\n",
    "    C_set = {}\n",
    "    for cand_spl in 'BC':\n",
    "        for key, value in ballot_counts.items():\n",
    "            if key[0] in 'EDFGHIJKLMNOPQRSTUVWXYZabcd'.replace(cand, \"\"):\n",
    "                if cand_spl in key:\n",
    "                    if 'A' in key and key.index('A')>key.index(cand_spl):\n",
    "                        C_set[cand_spl] = C_set.get(cand_spl, 0) + value\n",
    "    AtransfersL = 0 \n",
    "    for key, value in fil_data.items():\n",
    "        if key[0] == 'A':\n",
    "            if len(key)>1 and key[1] in 'DEFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "                AtransfersL = AtransfersL + value\n",
    "\n",
    "        SV0 = get_new_dict(fil_data)['A'] - Q \n",
    "        surplusA[cand] = SV0* (AtransfersL)/(SV0+A_original) - min(get_new_dict(fil_data)['B']+C_set['B'], get_new_dict(fil_data)['C']+C_set['C'])+A_needs\n",
    "        \n",
    "final_dict = {}\n",
    "another_dict = {}\n",
    "for cand in 'DEFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "    letter_counts ={}\n",
    "    \n",
    "    #strict_support\n",
    "    for key, value in ballot_counts.items():\n",
    "        i = 0\n",
    "        newset = []\n",
    "        if key and key[0] not in ['A']:\n",
    "            while key[i] in 'ADEFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "                newset.append(key[i])\n",
    "                i=i+1\n",
    "                if i >= len(key):\n",
    "                    break\n",
    "\n",
    "        new_key = ''.join(char for char in newset)\n",
    "        if cand in new_key:\n",
    "            if cand in letter_counts:\n",
    "                letter_counts[cand] += value\n",
    "            else:\n",
    "                letter_counts[cand] = value\n",
    "    final_dict[cand] =    -  round(surplusA[cand]+letter_counts[cand], 2)\n",
    "    #print(cand, final_dict[cand])\n",
    "    another_dict[cand] = 2*(letter_counts[cand] - strict_support(ballot_counts, 'DEFGHIJKLMNOPQRSTUVWXYZabcd', '', cand))\n",
    "    #print(cand, letter_counts[cand], 2*(letter_counts[cand] - strict_support(ballot_counts, 'DEFGHIJKLMNOPQRSTUVWXYZabcd', '', cand)))\n",
    "\n",
    "maxdev = min(final_dict, key=final_dict.get)   \n",
    "\n",
    "#print(final_dict)\n",
    "print(round(final_dict[maxdev]/84353*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time =  0.0263519287109375\n",
      "{'ABC': [0, []], 'ABD': [11243, {'D': 11243}]}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "budget = 84353 *0.134 #= 4216.15\n",
    "strats_frame = reach_any_winners_campaign(candidates, 3, Q, filtered_data, budget)\n",
    "#strats_frame = reach_any_order_campaign(candidates, 3, Q, filtered_data, budget)\n",
    "end = time.time()\n",
    "print('total time = ' , end - start)\n",
    "print( strats_frame)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D'] EFGHIJKLMNOPQRSTUVWXYZabcd True\n"
     ]
    }
   ],
   "source": [
    "candidates_reduced, group_remaining, stop = remove_irrelevent( ballot_counts, ['A', 'B', 'C', 'D', 'E', 'F', 'G'], \n",
    "                results[:20],84323 *0.05, 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcd')\n",
    "\n",
    "print(candidates_reduced, group_remaining, stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEBCD ['B', 'C', 'D', 'E', 'F']\n",
      "['B', 'C', 'D'] FE True\n"
     ]
    }
   ],
   "source": [
    "small_election_number = 25 #start after -- rounds are complete\n",
    "\n",
    "group = ''.join(char for char in [rt[i][0] for i in range(small_election_number, len(rt))])\n",
    "ballot_counts_short = collection[small_election_number][0]\n",
    "test = [rt[i][0] for i in range(small_election_number, len(rt))]\n",
    "ordered_test = sorted(test, key=lambda x: results.index(x))\n",
    "\n",
    "print(group, ordered_test)\n",
    "\n",
    "candidates_reduced, group_remaining, stop = remove_irrelevent(ballot_counts_short, ['A', 'B', 'C', 'D', 'E', 'F', 'G'], \n",
    "                ordered_test,84323*0.123 , group)\n",
    "\n",
    "print(candidates_reduced, group_remaining, stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time =  0.41860389709472656\n",
      "{'BC': [0, []], 'BD': [11149.999999999978, {'D': 11149.999999999985}], 'BF': [11982.999999999978, {'F': 11982.999999999982}], 'CD': [12450.999999999978, {'C': 651.0, 'D': 11799.999999999985}]}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "strats_frame = reach_any_winners_campaign(ordered_test, 2, Q, ballot_counts_short, 84323*0.15)\n",
    "#strats_frame = reach_any_order_campaign(ordered_test, 2, Q, ballot_counts_short, 84323*0.05)\n",
    "\n",
    "end = time.time()\n",
    "print('total time = ' , end - start)\n",
    "print( strats_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### District 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76563\n",
      "A 24864\n",
      "B 16100\n",
      "C 10694\n",
      "D 11410\n",
      "F 8116\n",
      "19141.75\n",
      "{'M': 2045, 'E': 6756, 'Q': 1276, 'H': 6052, 'I': 3314, 'G': 5304, 'O': 2338, 'S': 809, 'N': 2142, 'J': 2699, 'V': 775, 'T': 858, 'W': 676, 'L': 2410, 'R': 1670, 'P': 1763, 'U': 919, 'K': 2550, 'a': 318, 'Y': 498, 'b': 333, 'X': 771, 'Z': 382, 'c': 365, 'd': 108}\n",
      "E\n",
      "[['d', 0], ['c', 0], ['A', 1], ['b', 0], ['a', 0], ['Z', 0], ['Y', 0], ['X', 0], ['W', 0], ['V', 0], ['U', 0], ['S', 0], ['T', 0], ['R', 0], ['Q', 0], ['P', 0], ['N', 0], ['M', 0], ['O', 0], ['K', 0], ['L', 0], ['J', 0], ['I', 0], ['G', 0], ['H', 0], ['E', 0], ['F', 0], ['B', 1], ['D', 0], ['C', 1]] {'A': 1, 'B': 1, 'C': 1, 'D': 0, 'E': 0, 'F': 0, 'G': 0, 'H': 0, 'I': 0, 'J': 0, 'K': 0, 'L': 0, 'M': 0, 'N': 0, 'O': 0, 'P': 0, 'Q': 0, 'R': 0, 'S': 0, 'T': 0, 'U': 0, 'V': 0, 'W': 0, 'X': 0, 'Y': 0, 'Z': 0, 'a': 0, 'b': 0, 'c': 0, 'd': 0}\n"
     ]
    }
   ],
   "source": [
    "candidates_mapping = {\n",
    "    \"Olivia Clark\": \"A\",\n",
    "    \"Mitch Green\": \"B\",\n",
    "    \"Eric Zimmerman\": \"C\",\n",
    "    \"Eli Arnold\": \"D\",\n",
    "    \"Chad Lykins\": \"E\",\n",
    "    \"Sarah Silkie\": \"F\",\n",
    "    \"Bob Weinstein\": \"G\",\n",
    "    \"Lisa Freeman\": \"H\",\n",
    "    \"Tony Morse\": \"I\",\n",
    "    \"Ben Hufford\": \"J\",\n",
    "    \"Kevin Goldsmith\": \"K\",\n",
    "    \"Andra Vltavin\": \"L\",\n",
    "    \"Stanley Penkin\": \"M\",\n",
    "    \"John Toran\": \"N\",\n",
    "    \"Chloe Mason\": \"O\",\n",
    "    \"Bob Callahan\": \"P\",\n",
    "    \"Moses Ross\": \"Q\",\n",
    "    \"Ciatta R Thompson\": \"R\",\n",
    "    \"Raquel Coyote\": \"S\",\n",
    "    \"Mike DiNapoli\": \"T\",\n",
    "    \"John J Goldsmith\": \"U\",\n",
    "    \"Chris Henry\": \"V\",\n",
    "    \"Joseph (Joe) Alfone\": \"W\",\n",
    "    \"Michael Trimble\": \"X\",\n",
    "    \"Kelly Doyle\": \"Y\",\n",
    "    \"Brandon Farley\": \"Z\",\n",
    "    \"Patrick Cashman\": \"a\",\n",
    "    \"Tony Schwartz\": \"b\",\n",
    "    \"Lee Odell\": \"c\",\n",
    "    \"L Christopher Regis\": \"d\"\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"/Users/saeesbox/Desktop/dis4.csv\")\n",
    "df = df.drop(columns = ['RowNumber'])\n",
    "df.head()\n",
    "\n",
    "# Initialize a dictionary to store the counts of each ballot type as strings\n",
    "ballot_counts = {}\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df.iterrows():\n",
    "    # Initialize an empty list to store valid candidates\n",
    "    valid_candidates = []\n",
    "    \n",
    "    # Iterate through columns rank1 to rank5\n",
    "    for i in range(1, 7):\n",
    "        candidate = row[f'Choice_{i}']\n",
    "        if candidate in candidates_mapping.keys():\n",
    "            valid_candidates.append(candidates_mapping[candidate])\n",
    "    \n",
    "\n",
    "    # Check if the ballot is empty (no valid candidates)\n",
    "    if valid_candidates:  # Skip empty ballots\n",
    "        \n",
    "        ballot_type = ''.join(valid_candidates)\n",
    "\n",
    "        # Add the weight to the count for this ballot type in the dictionary\n",
    "        if ballot_type not in ballot_counts:\n",
    "            ballot_counts[ballot_type] = 1\n",
    "        else:\n",
    "            ballot_counts[ballot_type] += 1\n",
    "\n",
    "print(sum(ballot_counts.values()))\n",
    "\n",
    "# Initialize a dictionary for filtered data\n",
    "filtered_data = {}\n",
    "\n",
    "# Remove letters {G, H, I, J, K, L} while retaining the rest of the string\n",
    "for key, value in ballot_counts.items():\n",
    "    new_key = ''.join(char for char in key if char not in 'EGHIJKLMNOPQRSTUVWXYZabcd')\n",
    "    filtered_data[new_key] =   filtered_data.get(new_key, 0) + value\n",
    "filtered_data.pop('', None)\n",
    "\n",
    "# aggre_v_dict = get_new_dict(filtered_data)\n",
    "# candidates = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "# for c in candidates:\n",
    "#     print(c, aggre_v_dict[c])\n",
    "\n",
    "candidates = [ 'A', 'B', 'C', 'D', 'F']#, 'G']#, 'C', 'D', 'E', 'F', 'G']\n",
    "#filtered_data  = ballot_counts\n",
    "full_aggre_v_dict = get_new_dict(ballot_counts)\n",
    "aggre_v_dict = get_new_dict(filtered_data)\n",
    "#print(aggre_v_dict)\n",
    "for c in candidates:\n",
    "    print(c, aggre_v_dict[c])                                                                           \n",
    "\n",
    "#print(aggre_v_dict)\n",
    "k=3\n",
    "Q = round(sum(full_aggre_v_dict[candidate] for candidate in list(candidates_mapping.values()))/(k+1)+1,3)\n",
    "print(Q)\n",
    "\n",
    "#strict support check\n",
    "group = 'EGHIJKLMNOPQRSTUVWXYZabcd'\n",
    "\n",
    "letter_counts = {}\n",
    "\n",
    "#strict_support\n",
    "for key, value in ballot_counts.items():\n",
    "    i = 0\n",
    "    newset = []\n",
    "    if key and key[i] in candidates_mapping.values():\n",
    "        while key[i] in group:\n",
    "            newset.append(key[i])\n",
    "            i=i+1\n",
    "            if i >= len(key):\n",
    "                break\n",
    "\n",
    "    new_key = ''.join(char for char in newset)\n",
    "    for letter in new_key:\n",
    "        if letter in letter_counts:\n",
    "            letter_counts[letter] += value\n",
    "        else:\n",
    "            letter_counts[letter] = value\n",
    "\n",
    "print(letter_counts)\n",
    "best_c_irrelevant = max(letter_counts, key=letter_counts.get)\n",
    "print(best_c_irrelevant)\n",
    "\n",
    "rt, dt, collection = STV_optimal_result_simple(list(candidates_mapping.values()), ballot_counts, 3, Q)\n",
    "print(rt,dt)\n",
    "results, subresults = return_main_sub(rt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6105951998379764 69030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_wins(filtered_data, candidates, Q, budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 5, 6, 11, 13, 13, 14, 17, 19, 25, 43, 55, 61, 62, 71, 115, 152, 165, 250, 256, 467, 543, 643, 657, 772, 852, 1586, 3490]\n",
      "{'B': 772, 'C': 3490, 'D': 1586, 'E': 657, 'F': 852, 'G': 543, 'H': 467, 'I': 643, 'J': 256, 'K': 71, 'L': 43, 'M': 250, 'N': 165, 'O': 115, 'P': 152, 'Q': 61, 'R': 62, 'S': 55, 'T': 25, 'U': 13, 'V': 14, 'W': 19, 'X': 13, 'Y': 17, 'Z': 5, 'a': 3, 'b': 11, 'c': 6, 'd': 2}\n",
      "5.75\n"
     ]
    }
   ],
   "source": [
    "secondchoice = {}\n",
    "for cand in list(candidates_mapping.values()):\n",
    "    for key, value in ballot_counts.items():\n",
    "        if key[0] == cand:\n",
    "            if len(key)>1 and key[1] =='A':\n",
    "                secondchoice[cand] = secondchoice.get(cand, 0) + value\n",
    "print(sorted(secondchoice.values()))\n",
    "print(secondchoice)\n",
    "print(Q - get_new_dict(ballot_counts)['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_0 = {}\n",
    "for key, value in ballot_counts.items():\n",
    "    new_key = ''.join(char for char in key if char not in 'A')\n",
    "    \n",
    "    filtered_data_0[new_key] =   filtered_data_0.get(new_key, 0) + value\n",
    "filtered_data_0.pop('', None)\n",
    "aggre_v_dict_0 = get_new_dict(filtered_data_0)\n",
    "mysum = 0\n",
    "for cand in list(candidates_mapping.values()):\n",
    "    \n",
    "    if cand == 'A':\n",
    "        print(full_aggre_v_dict[cand])\n",
    "    else:\n",
    "        print(cand, (aggre_v_dict_0[cand] - full_aggre_v_dict[cand]))\n",
    "        mysum = mysum + aggre_v_dict_0[cand] - full_aggre_v_dict[cand]\n",
    "print(mysum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E': 7683.64, 'F': 6401.63, 'G': 8662.4, 'H': 8205.31, 'I': 12059.15, 'J': 11327.47, 'K': 14490.55, 'L': 15231.06, 'M': 14073.45, 'N': 13634.44, 'O': 14767.45, 'P': 14513.32, 'Q': 15973.29, 'R': 15697.27, 'S': 17512.11, 'T': 17092.91, 'U': 17522.04, 'V': 17409.72, 'W': 17724.33, 'X': 17465.33, 'Y': 17668.06, 'Z': 18027.73, 'a': 18106.47, 'b': 18139.25, 'c': 18224.78, 'd': 18509.56}\n",
      "8.36\n",
      "9.626777947572588\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "surplusA = {}\n",
    "A_original = get_new_dict(ballot_counts)['A']\n",
    "A_needs = Q - A_original\n",
    "for cand in 'EFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "    fil_data = {}\n",
    "    for key, value in ballot_counts.items():\n",
    "        \n",
    "        new_key = ''.join(char for char in key if char not in 'EDFGHIJKLMNOPQRSTUVWXYZabcd'.replace(cand, \"\"))\n",
    "        \n",
    "        fil_data[new_key] =   fil_data.get(new_key, 0) + value\n",
    "\n",
    "    fil_data.pop('', None)\n",
    "    C_set = {}\n",
    "    for cand_spl in 'BC':\n",
    "        for key, value in ballot_counts.items():\n",
    "            if key[0] in 'EDFGHIJKLMNOPQRSTUVWXYZabcd'.replace(cand, \"\"):\n",
    "                if cand_spl in key:\n",
    "                    if 'A' in key and key.index('A')>key.index(cand_spl):\n",
    "                        C_set[cand_spl] = C_set.get(cand_spl, 0) + value\n",
    "\n",
    "    AtransfersL = 0 \n",
    "    for key, value in fil_data.items():\n",
    "        if key[0] == 'A':\n",
    "            if len(key)>1 and key[1] in 'EDFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "                AtransfersL = AtransfersL + value\n",
    "        \n",
    "    SV0 = min(10, get_new_dict(fil_data)['A'] - Q )\n",
    "    #print(SV0)\n",
    "    #print(SV0* (AtransfersL)/(SV0+A_original))\n",
    "    surplusA[cand] = SV0* (AtransfersL)/(SV0+A_original) - min(get_new_dict(fil_data)['B']+C_set['B'], get_new_dict(fil_data)['C']+C_set['C'])#, get_new_dict(fil_data)['D']+C_set['D'])+A_needs\n",
    "        \n",
    "final_dict = {}\n",
    "another_dict = {}\n",
    "for cand in 'EFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "    letter_counts ={}\n",
    "    \n",
    "    #strict_support\n",
    "    for key, value in ballot_counts.items():\n",
    "        i = 0\n",
    "        newset = []\n",
    "        if key and key[0] not in ['A']:\n",
    "            while key[i] in 'AEDFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "                newset.append(key[i])\n",
    "                i=i+1\n",
    "                if i >= len(key):\n",
    "                    break\n",
    "\n",
    "        new_key = ''.join(char for char in newset)\n",
    "        if cand in new_key:\n",
    "            if cand in letter_counts:\n",
    "                letter_counts[cand] += value\n",
    "            else:\n",
    "                letter_counts[cand] = value\n",
    "    final_dict[cand] =    -  round(surplusA[cand]+letter_counts[cand], 2)\n",
    "    \n",
    "maxdev = min(final_dict, key=final_dict.get)   \n",
    "\n",
    "print(final_dict)\n",
    "\n",
    "print(round(final_dict[maxdev]/76563*100,2))\n",
    "print(7370.55/76563*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time =  0.6932637691497803\n",
      "{'ABC': [0, []], 'ABD': [1164, {'D': 1164}]}\n"
     ]
    }
   ],
   "source": [
    "# aggre_v_dict['F'] = aggre_v_dict['F'] + 3866\n",
    "\n",
    "budget = 76563*0.096\n",
    "start = time.time()\n",
    "strats_frame = reach_any_winners_campaign(candidates, 3, Q, filtered_data, budget)\n",
    "#strats_frame = reach_any_order_campaign(candidates, 3, Q, filtered_data, budget)\n",
    "end = time.time()\n",
    "print('total time = ' , end - start)\n",
    "print( strats_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EFBDC ['B', 'C', 'D', 'F', 'E']\n",
      "['B', 'C', 'D'] EF True\n"
     ]
    }
   ],
   "source": [
    "small_election_number = 25 #start after -- rounds are complete\n",
    "\n",
    "group = ''.join(char for char in [rt[i][0] for i in range(small_election_number, len(rt))])\n",
    "ballot_counts_short = collection[small_election_number][0]\n",
    "test = [rt[i][0] for i in range(small_election_number, len(rt))]\n",
    "ordered_test = sorted(test, key=lambda x: results.index(x))\n",
    "\n",
    "print(group, ordered_test)\n",
    "\n",
    "candidates_reduced, group_remaining, stop = remove_irrelevent(ballot_counts_short, ['A', 'B', 'C', 'D', 'E', 'F', 'G'], \n",
    "                ordered_test,76563*0.09 , group)\n",
    "\n",
    "print(candidates_reduced, group_remaining, stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D']\n"
     ]
    }
   ],
   "source": [
    "candidates_reduced, group_remaining, stop = remove_irrelevent( ballot_counts, rt, \n",
    "                results[:15],76563*0.05 , 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcd')\n",
    "print(candidates_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343.01151796907646\n"
     ]
    }
   ],
   "source": [
    "rt1, dt1, collection1 = STV_optimal_result_simple(ordered_test, ballot_counts_short, 2, Q)\n",
    "print(collection1[0][0]['DF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time =  0.3645620346069336\n",
      "{'BC': [0, []], 'BD': [835.0, {'D': 835.0}]}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "strats_frame = reach_any_winners_campaign(ordered_test, 2, Q, ballot_counts_short, 76563*0.05)\n",
    "#strats_frame = reach_any_order_campaign(ordered_test, 2, Q, ballot_counts_short, 76563*0.05)\n",
    "\n",
    "end = time.time()\n",
    "print('total time = ' , end - start)\n",
    "print( strats_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 100\n",
      "83 100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Create a mapping from candidate names to variables\n",
    "candidates_mapping = {\n",
    "    \"Candace Avalos\": \"A\",\n",
    "    \"Jamie Dunphy\": \"B\",\n",
    "    \"Loretta Smith\": \"C\",\n",
    "    \"Noah Ernst\": \"E\",\n",
    "    \"Terrence Hayes\":\"D\",\n",
    "    \"Steph Routh\": \"F\",\n",
    "    \"Timur Ender\": \"G\",\n",
    "    \"Doug Clove\": \"H\",\n",
    "    \"Peggy Sue Owens\": \"I\",\n",
    "    \"David Linn\": \"J\",\n",
    "    \"Joe Allen\": \"K\",\n",
    "    \"Michael (Mike) Sands\": \"L\",\n",
    "    \"Deian Salazar\": \"M\",\n",
    "    \"Cayle Tern\": \"N\",\n",
    "    \"Thomas Shervey\": \"O\",\n",
    "    \"Joe Furi\": \"P\"\n",
    "}\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = \"iteration_results_dis1_final\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # final: bootstrap_samples_dir = 'bootstrap_samples_new_3'\n",
    "# bootstrap_samples_dir = 'bootstrap_samples_new_dis1'\n",
    "\n",
    "# # List all files in the directory\n",
    "# bootstrap_files = os.listdir(bootstrap_samples_dir)\n",
    "\n",
    "# # Shuffle the list of files\n",
    "# random.shuffle(bootstrap_files)  # Randomizes the order\n",
    "\n",
    "# # Select the first 100 files\n",
    "# selected_files = bootstrap_files[:100]\n",
    "it = 0\n",
    "budget = 42686 * 0.04\n",
    "\n",
    "algo_works = 0\n",
    "fast_algo = 0 \n",
    "data_samples = []\n",
    "\n",
    "# Loop over each file and load it as a DataFrame\n",
    "for file in selected_files:\n",
    "    start = time.time()\n",
    "\n",
    "    it += 1\n",
    "    \n",
    "\n",
    "    sample_file_path = os.path.join(bootstrap_samples_dir, file)\n",
    "    \n",
    "    df = pd.read_csv(sample_file_path)\n",
    "\n",
    "    # Initialize a dictionary to store the counts of each ballot type as strings\n",
    "    ballot_counts = {}\n",
    "    Q = 10672.5\n",
    "\n",
    "    # Iterate through the DataFrame rows\n",
    "    for index, row in df.iterrows():\n",
    "        # Initialize an empty list to store valid candidates\n",
    "        valid_candidates = []\n",
    "        \n",
    "        # Iterate through columns Choice_1 to Choice_6\n",
    "        for i in range(1, 7):\n",
    "            candidate = row[f'Choice_{i}']\n",
    "            if candidate in candidates_mapping.keys():\n",
    "                valid_candidates.append(candidates_mapping[candidate])\n",
    "\n",
    "        # Check if the ballot is empty (no valid candidates)\n",
    "        if valid_candidates:  \n",
    "            ballot_type = ''.join(valid_candidates)\n",
    "\n",
    "            # Add the weight to the count for this ballot type in the dictionary\n",
    "            ballot_counts[ballot_type] = ballot_counts.get(ballot_type, 0) + 1\n",
    "            \n",
    "    # Compute results using STV\n",
    "    rt, dt, collection = STV_optimal_result_simple(list(candidates_mapping.values()), ballot_counts, 3, Q)\n",
    "    results, subresults = return_main_sub(rt)\n",
    "    \n",
    "    candidates_reduced, group, stop = remove_irrelevent(ballot_counts, results[-7:], \n",
    "                results[:7], budget, 'ABCDEFGHIJKLMNOP')\n",
    "    \n",
    "    if stop == False:\n",
    "        candidates_reduced, group, stop = remove_irrelevent(ballot_counts, results[-7:], \n",
    "                results[:8], budget, 'ABCDEFGHIJKLMNOP')\n",
    "    \n",
    "    if stop==True:\n",
    "        algo_works += 1\n",
    "        if len(candidates_reduced)<8:\n",
    "            fast_algo +=1\n",
    "        #print(f\"Iteration {it}: Candidates = {candidates_reduced}\")\n",
    "\n",
    "        # # Initialize a dictionary for filtered data\n",
    "        # filtered_data = {}\n",
    "\n",
    "        # # Remove letters {G, H, I, J, K, L} while retaining the rest of the string\n",
    "        # for key, value in ballot_counts.items():\n",
    "        #     new_key = ''.join(char for char in key if char not in group)\n",
    "        #     filtered_data[new_key] = filtered_data.get(new_key, 0) + value\n",
    "        # filtered_data.pop('', None)\n",
    "\n",
    "        # strats_frame = reach_any_winners_campaign(candidates_reduced, 3, Q, filtered_data, budget)\n",
    "        # data_samples.append(strats_frame)\n",
    "\n",
    "        # save_path = os.path.join(output_dir, f\"iteration_{it}.json\")\n",
    "        # with open(save_path, \"w\") as f:\n",
    "        #     json.dump({\"iteration\": it, \"strats_frame\": strats_frame}, f, indent=4)\n",
    "\n",
    "        # print(f\"Iteration {it}: strats_frame = {strats_frame}\")\n",
    "    \n",
    "    end = time.time()    \n",
    "    #print('Total time =', end - start)\n",
    "print(algo_works, it)\n",
    "print(fast_algo, it)\n",
    "\n",
    "# 997 1000 all removals\n",
    "# 807 1000 all 9 candidate removals \n",
    "# 865 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Strategies under uncertainty- bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### primary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time =  35.333735942840576\n",
      "Counter({'AB': 688, 'AC': 244, 'AD': 53, 'AE': 15})\n"
     ]
    }
   ],
   "source": [
    "# primary experiments\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "bootstrap_samples_dir = 'bootstrap_samples_new_3'\n",
    "\n",
    "# List all files in the directory\n",
    "bootstrap_files = os.listdir(bootstrap_samples_dir)\n",
    "\n",
    "strats_under_uncertainty = []\n",
    "\n",
    "data_samples = []\n",
    "it = 0 \n",
    "# Loop over each file and load it as a DataFrame\n",
    "for file in bootstrap_files:\n",
    "    stop = False\n",
    "    it=it+1\n",
    "    sample_file_path = os.path.join(bootstrap_samples_dir, file)\n",
    "    \n",
    "    df = pd.read_csv(sample_file_path)\n",
    "    \n",
    "    #df = df.drop(columns = ['record', 'QBASE'])\n",
    "\n",
    "    # Initialize a dictionary to store the counts of each ballot type as strings\n",
    "    ballot_counts = {}\n",
    "    Q = 800\n",
    "\n",
    "    # Iterate through the DataFrame rows\n",
    "    for index, row in df.iterrows():\n",
    "        # Initialize an empty list to store valid candidates\n",
    "        valid_candidates = []\n",
    "\n",
    "        # Iterate through columns rank1 to rank5\n",
    "        for i in range(1, 14):\n",
    "            candidate = row[f'rank{i}']\n",
    "            valid_candidates.append(candidates_mapping[candidate])\n",
    "\n",
    "\n",
    "        ballot_type = ''.join(valid_candidates)\n",
    "\n",
    "        # Use the 'weight' column to determine the number of voters for this ballot type\n",
    "        weight = row['weight']\n",
    "\n",
    "        # Add the weight to the count for this ballot type in the dictionary\n",
    "        if ballot_type not in ballot_counts:\n",
    "            ballot_counts[ballot_type] = weight\n",
    "        else:\n",
    "            ballot_counts[ballot_type] += weight\n",
    "            \n",
    "    df['weight'] = df['weight']*800/df['weight'].sum()\n",
    "    #ballot_counts['EC'] = 10\n",
    "    \n",
    "    \n",
    "    \n",
    "    results = IRV_optimal_result(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M'], ballot_counts)\n",
    "    strats_under_uncertainty. append(''.join(results[:2]))\n",
    "\n",
    "    \n",
    "end = time.time()    \n",
    "print('total time = ' , end - start)\n",
    "\n",
    "frequency = Counter(strats_under_uncertainty)\n",
    "\n",
    "# Displaying the frequency of each element\n",
    "print(frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bootstrap creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_bootstrap_samples(data, n_samples=1000):\n",
    "    \"\"\"\n",
    "    Generates bootstrap samples from the given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    data (DataFrame): The original dataset containing RCV rankings.\n",
    "    n_samples (int): The number of bootstrap samples to generate.\n",
    "\n",
    "    Returns:\n",
    "    List[DataFrame]: A list containing the bootstrap samples.\n",
    "    \"\"\"\n",
    "    bootstrap_samples = []\n",
    "    n = len(data)\n",
    "    for _ in range(n_samples):\n",
    "        sample = data.sample(n, replace=True)  # Sampling with replacement\n",
    "        bootstrap_samples.append(sample)\n",
    "    return bootstrap_samples\n",
    "\n",
    "\n",
    "n_bootstrap_samples = 100  # You can change this to your desired number of samples\n",
    "bootstrap_samples = generate_bootstrap_samples(df, n_bootstrap_samples)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Creating a directory to store all the bootstrap sample files\n",
    "output_dir = 'bootstrap_samples_new_dis3'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Saving each bootstrap sample as a separate CSV file\n",
    "for i, sample in enumerate(bootstrap_samples):\n",
    "    sample_file_path = os.path.join(output_dir, f'bootstrap_sample_{i+1}.csv')\n",
    "    sample.to_csv(sample_file_path, index=False)\n",
    "\n",
    "# # Creating a ZIP file of all the bootstrap sample files\n",
    "# import shutil\n",
    "# zip_file_path = 'bootstrap_samples_new.zip'\n",
    "# shutil.make_archive(base_name=os.path.splitext(zip_file_path)[0], format='zip', root_dir=output_dir)\n",
    "\n",
    "# zip_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = \"iteration_results_dis2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# final: bootstrap_samples_dir = 'bootstrap_samples_new_3'\n",
    "bootstrap_samples_dir = 'bootstrap_samples_new_dis2'\n",
    "\n",
    "# List all files in the directory\n",
    "bootstrap_files = os.listdir(bootstrap_samples_dir)\n",
    "it = 0\n",
    "budget = 77036*0.06 #76563*0.05\n",
    "\n",
    "algo_works = 0\n",
    "data_samples = []\n",
    "\n",
    "# Loop over each file and load it as a DataFrame\n",
    "for file in bootstrap_files:\n",
    "    start = time.time()\n",
    "    \n",
    "    stop = False\n",
    "    it += 1\n",
    "    if it > 100:\n",
    "        break\n",
    "\n",
    "    sample_file_path = os.path.join(bootstrap_samples_dir, file)\n",
    "    \n",
    "    df = pd.read_csv(sample_file_path)\n",
    "\n",
    "    # Initialize a dictionary to store the counts of each ballot type as strings\n",
    "    ballot_counts = {}\n",
    "    #Q = 19141.75\n",
    "\n",
    "    # Iterate through the DataFrame rows\n",
    "    for index, row in df.iterrows():\n",
    "        # Initialize an empty list to store valid candidates\n",
    "        valid_candidates = []\n",
    "        \n",
    "        # Iterate through columns Choice_1 to Choice_6\n",
    "        for i in range(1, 7):\n",
    "            candidate = row[f'Choice_{i}']\n",
    "            if candidate in candidates_mapping.keys():\n",
    "                valid_candidates.append(candidates_mapping[candidate])\n",
    "\n",
    "        # Check if the ballot is empty (no valid candidates)\n",
    "        if valid_candidates:  \n",
    "            ballot_type = ''.join(valid_candidates)\n",
    "\n",
    "            # Add the weight to the count for this ballot type in the dictionary\n",
    "            ballot_counts[ballot_type] = ballot_counts.get(ballot_type, 0) + 1\n",
    "            \n",
    "    # Compute results using STV\n",
    "    rt, dt, collection = STV_optimal_result_simple(list(candidates_mapping.values()), ballot_counts, 3, Q)\n",
    "    results, subresults = return_main_sub(rt)\n",
    "\n",
    "    # small_election_number = 25 #start after -- rounds are complete\n",
    "\n",
    "    # group = ''.join(char for char in [rt[i][0] for i in range(small_election_number, len(rt))])\n",
    "    # ballot_counts_short = collection[small_election_number][0]\n",
    "    # test = [rt[i][0] for i in range(small_election_number, len(rt))]\n",
    "    # ordered_test = sorted(test, key=lambda x: results.index(x))\n",
    "\n",
    "    # print(group, ordered_test)\n",
    "\n",
    "    # candidates_reduced, group_remaining, stop = remove_irrelevent(ballot_counts_short, ['A', 'B', 'C', 'D', 'E', 'F', 'G'], \n",
    "    #                 ordered_test,76563*0.05 , group)\n",
    "\n",
    "    \n",
    "    candidates_reduced, group, stop = remove_irrelevent(ballot_counts, results[-7:], \n",
    "                results[:6], budget, 'ABCDEFGHIJKLMNOPQRSTUV')\n",
    "    \n",
    "    print(f\"Iteration {it}: Candidates = {candidates_reduced}\")\n",
    "    \n",
    "    if stop:\n",
    "        algo_works += 1\n",
    "\n",
    "        # Initialize a dictionary for filtered data\n",
    "        filtered_data = {}\n",
    "\n",
    "        # Remove letters {G, H, I, J, K, L} while retaining the rest of the string\n",
    "        for key, value in ballot_counts.items():\n",
    "            new_key = ''.join(char for char in key if char not in group)\n",
    "            filtered_data[new_key] = filtered_data.get(new_key, 0) + value\n",
    "        filtered_data.pop('', None)\n",
    "\n",
    "        #strats_frame = reach_any_winners_campaign(ordered_test, 3, Q, ballot_counts_short, budget)\n",
    "   \n",
    "        strats_frame = reach_any_winners_campaign(candidates_reduced, 3, Q, filtered_data, budget)\n",
    "        data_samples.append(strats_frame)\n",
    "\n",
    "        save_path = os.path.join(output_dir, f\"iteration_{it}.json\")\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump({\"iteration\": it, \"strats_frame\": strats_frame}, f, indent=4)\n",
    "\n",
    "        print(f\"Iteration {it}: strats_frame = {strats_frame}\")\n",
    "    \n",
    "    end = time.time()    \n",
    "    print('Total time =', end - start)\n",
    "print(algo_works, it)\n",
    "print(strats_frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### District 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.27\n",
      "Iteration 1: Candidates = ['A', 'B', 'C']\n",
      "12.23\n",
      "Iteration 2: Candidates = ['A', 'B', 'C']\n",
      "12.01\n",
      "Iteration 3: Candidates = ['A', 'B', 'C']\n",
      "12.09\n",
      "Iteration 4: Candidates = ['A', 'B', 'C']\n",
      "12.07\n",
      "Iteration 5: Candidates = ['A', 'B', 'C']\n",
      "12.83\n",
      "Iteration 6: Candidates = ['A', 'B', 'C']\n",
      "12.45\n",
      "Iteration 7: Candidates = ['A', 'B', 'C']\n",
      "11.9\n",
      "Iteration 8: Candidates = ['A', 'B', 'C']\n",
      "12.5\n",
      "Iteration 9: Candidates = ['A', 'B', 'C']\n",
      "11.86\n",
      "Iteration 10: Candidates = ['A', 'B', 'C']\n",
      "12.39\n",
      "Iteration 11: Candidates = ['A', 'B', 'C']\n",
      "12.34\n",
      "Iteration 12: Candidates = ['A', 'B', 'C']\n",
      "12.55\n",
      "Iteration 13: Candidates = ['A', 'B', 'C']\n",
      "12.35\n",
      "Iteration 14: Candidates = ['A', 'B', 'C']\n",
      "11.79\n",
      "Iteration 15: Candidates = ['A', 'B', 'C']\n",
      "11.87\n",
      "Iteration 16: Candidates = ['A', 'B', 'C']\n",
      "12.71\n",
      "Iteration 17: Candidates = ['A', 'B', 'C']\n",
      "12.22\n",
      "Iteration 18: Candidates = ['A', 'B', 'C']\n",
      "12.28\n",
      "Iteration 19: Candidates = ['A', 'B', 'C']\n",
      "12.35\n",
      "Iteration 20: Candidates = ['A', 'B', 'C']\n",
      "11.87\n",
      "Iteration 21: Candidates = ['A', 'B', 'C']\n",
      "12.56\n",
      "Iteration 22: Candidates = ['A', 'B', 'C']\n",
      "12.26\n",
      "Iteration 23: Candidates = ['A', 'B', 'C']\n",
      "12.29\n",
      "Iteration 24: Candidates = ['A', 'B', 'C']\n",
      "12.31\n",
      "Iteration 25: Candidates = ['A', 'B', 'C']\n",
      "12.23\n",
      "Iteration 26: Candidates = ['A', 'B', 'C']\n",
      "12.13\n",
      "Iteration 27: Candidates = ['A', 'B', 'C']\n",
      "12.1\n",
      "Iteration 28: Candidates = ['A', 'B', 'C']\n",
      "11.96\n",
      "Iteration 29: Candidates = ['A', 'B', 'C']\n",
      "12.55\n",
      "Iteration 30: Candidates = ['A', 'B', 'C']\n",
      "12.35\n",
      "Iteration 31: Candidates = ['A', 'B', 'C']\n",
      "12.0\n",
      "Iteration 32: Candidates = ['A', 'B', 'C']\n",
      "12.08\n",
      "Iteration 33: Candidates = ['A', 'B', 'C']\n",
      "12.22\n",
      "Iteration 34: Candidates = ['A', 'B', 'C']\n",
      "12.27\n",
      "Iteration 35: Candidates = ['A', 'B', 'C']\n",
      "12.29\n",
      "Iteration 36: Candidates = ['A', 'B', 'C']\n",
      "12.01\n",
      "Iteration 37: Candidates = ['A', 'B', 'C']\n",
      "12.35\n",
      "Iteration 38: Candidates = ['A', 'B', 'C']\n",
      "12.2\n",
      "Iteration 39: Candidates = ['A', 'B', 'C']\n",
      "12.25\n",
      "Iteration 40: Candidates = ['A', 'B', 'C']\n",
      "12.25\n",
      "Iteration 41: Candidates = ['A', 'B', 'C']\n",
      "12.19\n",
      "Iteration 42: Candidates = ['A', 'B', 'C']\n",
      "12.09\n",
      "Iteration 43: Candidates = ['A', 'B', 'C']\n",
      "12.04\n",
      "Iteration 44: Candidates = ['A', 'B', 'C']\n",
      "11.78\n",
      "Iteration 45: Candidates = ['A', 'B', 'C']\n",
      "12.38\n",
      "Iteration 46: Candidates = ['A', 'B', 'C']\n",
      "12.36\n",
      "Iteration 47: Candidates = ['A', 'B', 'C']\n",
      "12.32\n",
      "Iteration 48: Candidates = ['A', 'B', 'C']\n",
      "12.0\n",
      "Iteration 49: Candidates = ['A', 'B', 'C']\n",
      "11.84\n",
      "Iteration 50: Candidates = ['A', 'B', 'C']\n",
      "12.32\n",
      "Iteration 51: Candidates = ['A', 'B', 'C']\n",
      "12.41\n",
      "Iteration 52: Candidates = ['A', 'B', 'C']\n",
      "12.12\n",
      "Iteration 53: Candidates = ['A', 'B', 'C']\n",
      "12.34\n",
      "Iteration 54: Candidates = ['A', 'B', 'C']\n",
      "12.2\n",
      "Iteration 55: Candidates = ['A', 'B', 'C']\n",
      "12.27\n",
      "Iteration 56: Candidates = ['A', 'B', 'C']\n",
      "12.48\n",
      "Iteration 57: Candidates = ['A', 'B', 'C']\n",
      "12.44\n",
      "Iteration 58: Candidates = ['A', 'B', 'C']\n",
      "12.03\n",
      "Iteration 59: Candidates = ['A', 'B', 'C']\n",
      "12.3\n",
      "Iteration 60: Candidates = ['A', 'B', 'C']\n",
      "12.53\n",
      "Iteration 61: Candidates = ['A', 'B', 'C']\n",
      "12.57\n",
      "Iteration 62: Candidates = ['A', 'B', 'C']\n",
      "12.31\n",
      "Iteration 63: Candidates = ['A', 'B', 'C']\n",
      "12.4\n",
      "Iteration 64: Candidates = ['A', 'B', 'C']\n",
      "12.16\n",
      "Iteration 65: Candidates = ['A', 'B', 'C']\n",
      "12.12\n",
      "Iteration 66: Candidates = ['A', 'B', 'C']\n",
      "12.03\n",
      "Iteration 67: Candidates = ['A', 'B', 'C']\n",
      "12.23\n",
      "Iteration 68: Candidates = ['A', 'B', 'C']\n",
      "12.27\n",
      "Iteration 69: Candidates = ['A', 'B', 'C']\n",
      "11.66\n",
      "Iteration 70: Candidates = ['A', 'B', 'C']\n",
      "12.38\n",
      "Iteration 71: Candidates = ['A', 'B', 'C']\n",
      "12.38\n",
      "Iteration 72: Candidates = ['A', 'B', 'C']\n",
      "12.11\n",
      "Iteration 73: Candidates = ['A', 'B', 'C']\n",
      "12.39\n",
      "Iteration 74: Candidates = ['A', 'B', 'C']\n",
      "11.9\n",
      "Iteration 75: Candidates = ['A', 'B', 'C']\n",
      "12.26\n",
      "Iteration 76: Candidates = ['A', 'B', 'C']\n",
      "12.4\n",
      "Iteration 77: Candidates = ['A', 'B', 'C']\n",
      "12.38\n",
      "Iteration 78: Candidates = ['A', 'B', 'C']\n",
      "11.77\n",
      "Iteration 79: Candidates = ['A', 'B', 'C']\n",
      "12.32\n",
      "Iteration 80: Candidates = ['A', 'B', 'C']\n",
      "12.13\n",
      "Iteration 81: Candidates = ['A', 'B', 'C']\n",
      "12.16\n",
      "Iteration 82: Candidates = ['A', 'B', 'C']\n",
      "12.51\n",
      "Iteration 83: Candidates = ['A', 'B', 'C']\n",
      "12.09\n",
      "Iteration 84: Candidates = ['A', 'B', 'C']\n",
      "12.35\n",
      "Iteration 85: Candidates = ['A', 'B', 'C']\n",
      "11.94\n",
      "Iteration 86: Candidates = ['A', 'B', 'C']\n",
      "11.81\n",
      "Iteration 87: Candidates = ['A', 'B', 'C']\n",
      "12.41\n",
      "Iteration 88: Candidates = ['A', 'B', 'C']\n",
      "11.99\n",
      "Iteration 89: Candidates = ['A', 'B', 'C']\n",
      "12.52\n",
      "Iteration 90: Candidates = ['A', 'B', 'C']\n",
      "12.28\n",
      "Iteration 91: Candidates = ['A', 'B', 'C']\n",
      "12.33\n",
      "Iteration 92: Candidates = ['A', 'B', 'C']\n",
      "12.49\n",
      "Iteration 93: Candidates = ['A', 'B', 'C']\n",
      "12.43\n",
      "Iteration 94: Candidates = ['A', 'B', 'C']\n",
      "12.23\n",
      "Iteration 95: Candidates = ['A', 'B', 'C']\n",
      "12.11\n",
      "Iteration 96: Candidates = ['A', 'B', 'C']\n",
      "12.21\n",
      "Iteration 97: Candidates = ['A', 'B', 'C']\n",
      "12.41\n",
      "Iteration 98: Candidates = ['A', 'B', 'C']\n",
      "12.22\n",
      "Iteration 99: Candidates = ['A', 'B', 'C']\n",
      "12.31\n",
      "Iteration 100: Candidates = ['A', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "## District 3\n",
    "import os \n",
    "bootstrap_samples_dir = 'bootstrap_samples_new_dis3'\n",
    "\n",
    "# List all files in the directory\n",
    "bootstrap_files = os.listdir(bootstrap_samples_dir)\n",
    "it = 0\n",
    "\n",
    "algo_works = 0\n",
    "data_samples = []\n",
    "\n",
    "# Loop over each file and load it as a DataFrame\n",
    "for file in bootstrap_files:\n",
    "    start = time.time()\n",
    "    \n",
    "    stop = False\n",
    "    it += 1\n",
    "    if it > 100:\n",
    "        break\n",
    "\n",
    "    sample_file_path = os.path.join(bootstrap_samples_dir, file)\n",
    "    \n",
    "    df = pd.read_csv(sample_file_path)\n",
    "\n",
    "    # Initialize a dictionary to store the counts of each ballot type as strings\n",
    "    ballot_counts = {}\n",
    "    #Q = 19141.75\n",
    "\n",
    "    # Iterate through the DataFrame rows\n",
    "    for index, row in df.iterrows():\n",
    "        # Initialize an empty list to store valid candidates\n",
    "        valid_candidates = []\n",
    "        \n",
    "        # Iterate through columns Choice_1 to Choice_6\n",
    "        for i in range(1, 7):\n",
    "            candidate = row[f'Choice_{i}']\n",
    "            if candidate in candidates_mapping.keys():\n",
    "                valid_candidates.append(candidates_mapping[candidate])\n",
    "\n",
    "        # Check if the ballot is empty (no valid candidates)\n",
    "        if valid_candidates:  \n",
    "            ballot_type = ''.join(valid_candidates)\n",
    "\n",
    "            # Add the weight to the count for this ballot type in the dictionary\n",
    "            ballot_counts[ballot_type] = ballot_counts.get(ballot_type, 0) + 1\n",
    "            \n",
    "            \n",
    "    surplusA = {}\n",
    "    A_original = get_new_dict(ballot_counts)['A']\n",
    "    A_needs = Q - A_original\n",
    "    for cand in 'DEFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "        fil_data = {}\n",
    "        for key, value in ballot_counts.items():\n",
    "        \n",
    "            new_key = ''.join(char for char in key if char not in 'DEFGHIJKLMNOPQRSTUVWXYZabcd'.replace(cand, \"\"))\n",
    "            \n",
    "            fil_data[new_key] =   fil_data.get(new_key, 0) + value\n",
    "        fil_data.pop('', None)\n",
    "        C_set = {}\n",
    "        for cand_spl in 'BC':\n",
    "            for key, value in ballot_counts.items():\n",
    "                if key[0] in 'EDFGHIJKLMNOPQRSTUVWXYZabcd'.replace(cand, \"\"):\n",
    "                    if cand_spl in key:\n",
    "                        if 'A' in key and key.index('A')>key.index(cand_spl):\n",
    "                            C_set[cand_spl] = C_set.get(cand_spl, 0) + value\n",
    "        AtransfersL = 0 \n",
    "        for key, value in fil_data.items():\n",
    "            if key[0] == 'A':\n",
    "                if len(key)>1 and key[1] in 'DEFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "                    AtransfersL = AtransfersL + value\n",
    "\n",
    "            SV0 = get_new_dict(fil_data)['A'] - Q \n",
    "            surplusA[cand] = SV0* (AtransfersL)/(SV0+A_original) - min(get_new_dict(fil_data)['B']+C_set['B'], get_new_dict(fil_data)['C']+C_set['C'])+A_needs\n",
    "        \n",
    "            \n",
    "    final_dict = {}\n",
    "    another_dict = {}\n",
    "    for cand in 'DEFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "        letter_counts ={}\n",
    "        \n",
    "        #strict_support\n",
    "        for key, value in ballot_counts.items():\n",
    "            i = 0\n",
    "            newset = []\n",
    "            if key and key[0] not in ['A']:\n",
    "                while key[i] in 'ADEFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "                    newset.append(key[i])\n",
    "                    i=i+1\n",
    "                    if i >= len(key):\n",
    "                        break\n",
    "\n",
    "            new_key = ''.join(char for char in newset)\n",
    "            if cand in new_key:\n",
    "                if cand in letter_counts:\n",
    "                    letter_counts[cand] += value\n",
    "                else:\n",
    "                    letter_counts[cand] = value\n",
    "        final_dict[cand] =    -  round(surplusA[cand]+letter_counts[cand], 2)\n",
    "        #print(cand, final_dict[cand])\n",
    "        another_dict[cand] = 2*(letter_counts[cand] - strict_support(ballot_counts, 'DEFGHIJKLMNOPQRSTUVWXYZabcd', '', cand))\n",
    "        #print(cand, letter_counts[cand], 2*(letter_counts[cand] - strict_support(ballot_counts, 'DEFGHIJKLMNOPQRSTUVWXYZabcd', '', cand)))\n",
    "    maxdev = min(final_dict, key=final_dict.get)   \n",
    "\n",
    "    #print(final_dict)\n",
    "    print(round(final_dict[maxdev]/84353*100,2))\n",
    "    rt, dt, collection = STV_optimal_result_simple(list(candidates_mapping.values()), ballot_counts, 3, Q)\n",
    "    results, subresults = return_main_sub(rt)\n",
    "    candidates_reduced, group, stop = remove_irrelevent(ballot_counts, results[-7:], \n",
    "                results[:3], 84353*0.11, 'ABCDEFGHIJKLMNOPQRSTUV')\n",
    "    \n",
    "    print(f\"Iteration {it}: Candidates = {candidates_reduced}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### District 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.47\n",
      "Iteration 1: Candidates = ['A', 'B']\n",
      "9.29\n",
      "Iteration 2: Candidates = ['A', 'B']\n",
      "9.93\n",
      "Iteration 3: Candidates = ['A', 'B']\n",
      "9.89\n",
      "Iteration 4: Candidates = ['A', 'B']\n",
      "9.31\n",
      "Iteration 5: Candidates = ['A', 'B']\n",
      "9.72\n",
      "Iteration 6: Candidates = ['A', 'B']\n",
      "9.54\n",
      "Iteration 7: Candidates = ['A', 'B']\n",
      "10.03\n",
      "Iteration 8: Candidates = ['A', 'B']\n",
      "9.51\n",
      "Iteration 9: Candidates = ['A', 'B']\n",
      "9.4\n",
      "Iteration 10: Candidates = ['A', 'B']\n",
      "9.77\n",
      "Iteration 11: Candidates = ['A', 'B']\n",
      "9.96\n",
      "Iteration 12: Candidates = ['A', 'B']\n",
      "9.34\n",
      "Iteration 13: Candidates = ['A', 'B']\n",
      "10.06\n",
      "Iteration 14: Candidates = ['A', 'B']\n",
      "9.68\n",
      "Iteration 15: Candidates = ['A', 'B']\n",
      "9.82\n",
      "Iteration 16: Candidates = ['A', 'B']\n",
      "9.68\n",
      "Iteration 17: Candidates = ['A', 'B']\n",
      "9.48\n",
      "Iteration 18: Candidates = ['A', 'B']\n",
      "9.47\n",
      "Iteration 19: Candidates = ['A', 'B']\n",
      "9.42\n",
      "Iteration 20: Candidates = ['A', 'B']\n",
      "9.68\n",
      "Iteration 21: Candidates = ['A', 'B']\n",
      "9.1\n",
      "Iteration 22: Candidates = ['A', 'B']\n",
      "9.61\n",
      "Iteration 23: Candidates = ['A', 'B']\n",
      "9.32\n",
      "Iteration 24: Candidates = ['A', 'B']\n",
      "9.67\n",
      "Iteration 25: Candidates = ['A', 'B']\n",
      "9.99\n",
      "Iteration 26: Candidates = ['A', 'B']\n",
      "9.33\n",
      "Iteration 27: Candidates = ['A', 'B']\n",
      "9.45\n",
      "Iteration 28: Candidates = ['A', 'B']\n",
      "9.49\n",
      "Iteration 29: Candidates = ['A', 'B']\n",
      "9.46\n",
      "Iteration 30: Candidates = ['A', 'B']\n",
      "9.72\n",
      "Iteration 31: Candidates = ['A', 'B']\n",
      "10.23\n",
      "Iteration 32: Candidates = ['A', 'B']\n",
      "9.88\n",
      "Iteration 33: Candidates = ['A', 'B']\n",
      "9.91\n",
      "Iteration 34: Candidates = ['A', 'B']\n",
      "9.35\n",
      "Iteration 35: Candidates = ['A', 'B']\n",
      "10.27\n",
      "Iteration 36: Candidates = ['A', 'B']\n",
      "9.81\n",
      "Iteration 37: Candidates = ['A', 'B']\n",
      "9.87\n",
      "Iteration 38: Candidates = ['A', 'B']\n",
      "9.62\n",
      "Iteration 39: Candidates = ['A', 'B']\n",
      "9.85\n",
      "Iteration 40: Candidates = ['A', 'B']\n",
      "9.46\n",
      "Iteration 41: Candidates = ['A', 'B']\n",
      "9.84\n",
      "Iteration 42: Candidates = ['A', 'B']\n",
      "9.84\n",
      "Iteration 43: Candidates = ['A', 'B']\n",
      "9.66\n",
      "Iteration 44: Candidates = ['A', 'B']\n",
      "9.35\n",
      "Iteration 45: Candidates = ['A', 'B']\n",
      "9.45\n",
      "Iteration 46: Candidates = ['A', 'B']\n",
      "9.61\n",
      "Iteration 47: Candidates = ['A', 'B']\n",
      "9.46\n",
      "Iteration 48: Candidates = ['A', 'B']\n",
      "9.61\n",
      "Iteration 49: Candidates = ['A', 'B']\n",
      "9.92\n",
      "Iteration 50: Candidates = ['A', 'B']\n",
      "9.72\n",
      "Iteration 51: Candidates = ['A', 'B']\n",
      "10.07\n",
      "Iteration 52: Candidates = ['A', 'B']\n",
      "9.48\n",
      "Iteration 53: Candidates = ['A', 'B']\n",
      "9.56\n",
      "Iteration 54: Candidates = ['A', 'B']\n",
      "9.62\n",
      "Iteration 55: Candidates = ['A', 'B']\n",
      "9.66\n",
      "Iteration 56: Candidates = ['A', 'B']\n",
      "9.84\n",
      "Iteration 57: Candidates = ['A', 'B']\n",
      "9.25\n",
      "Iteration 58: Candidates = ['A', 'B']\n",
      "9.44\n",
      "Iteration 59: Candidates = ['A', 'B']\n",
      "9.53\n",
      "Iteration 60: Candidates = ['A', 'B']\n",
      "10.09\n",
      "Iteration 61: Candidates = ['A', 'B']\n",
      "9.28\n",
      "Iteration 62: Candidates = ['A', 'B']\n",
      "9.85\n",
      "Iteration 63: Candidates = ['A', 'B']\n",
      "9.46\n",
      "Iteration 64: Candidates = ['A', 'B']\n",
      "9.68\n",
      "Iteration 65: Candidates = ['A', 'B']\n",
      "9.61\n",
      "Iteration 66: Candidates = ['A', 'B']\n",
      "10.2\n",
      "Iteration 67: Candidates = ['A', 'B']\n",
      "9.48\n",
      "Iteration 68: Candidates = ['A', 'B']\n",
      "9.78\n",
      "Iteration 69: Candidates = ['A', 'B']\n",
      "9.55\n",
      "Iteration 70: Candidates = ['A', 'B']\n",
      "9.59\n",
      "Iteration 71: Candidates = ['A', 'B']\n",
      "9.36\n",
      "Iteration 72: Candidates = ['A', 'B']\n",
      "9.43\n",
      "Iteration 73: Candidates = ['A', 'B']\n",
      "9.96\n",
      "Iteration 74: Candidates = ['A', 'B']\n",
      "9.56\n",
      "Iteration 75: Candidates = ['A', 'B']\n",
      "9.74\n",
      "Iteration 76: Candidates = ['A', 'B']\n",
      "9.63\n",
      "Iteration 77: Candidates = ['A', 'B']\n",
      "9.62\n",
      "Iteration 78: Candidates = ['A', 'B']\n",
      "9.73\n",
      "Iteration 79: Candidates = ['A', 'B']\n",
      "9.64\n",
      "Iteration 80: Candidates = ['A', 'B']\n",
      "10.0\n",
      "Iteration 81: Candidates = ['A', 'B']\n",
      "9.77\n",
      "Iteration 82: Candidates = ['A', 'B']\n",
      "9.84\n",
      "Iteration 83: Candidates = ['A', 'B']\n",
      "9.81\n",
      "Iteration 84: Candidates = ['A', 'B']\n",
      "10.15\n",
      "Iteration 85: Candidates = ['A', 'B']\n",
      "9.71\n",
      "Iteration 86: Candidates = ['A', 'B']\n",
      "9.7\n",
      "Iteration 87: Candidates = ['A', 'B']\n",
      "9.45\n",
      "Iteration 88: Candidates = ['A', 'B']\n",
      "9.55\n",
      "Iteration 89: Candidates = ['A', 'B']\n",
      "9.65\n",
      "Iteration 90: Candidates = ['A', 'B']\n",
      "9.84\n",
      "Iteration 91: Candidates = ['A', 'B']\n",
      "9.39\n",
      "Iteration 92: Candidates = ['A', 'B']\n",
      "9.94\n",
      "Iteration 93: Candidates = ['A', 'B']\n",
      "9.75\n",
      "Iteration 94: Candidates = ['A', 'B']\n",
      "9.78\n",
      "Iteration 95: Candidates = ['A', 'B']\n",
      "9.38\n",
      "Iteration 96: Candidates = ['A', 'B']\n",
      "9.78\n",
      "Iteration 97: Candidates = ['A', 'B']\n",
      "9.37\n",
      "Iteration 98: Candidates = ['A', 'B']\n",
      "9.3\n",
      "Iteration 99: Candidates = ['A', 'B']\n",
      "9.51\n",
      "Iteration 100: Candidates = ['A', 'B']\n"
     ]
    }
   ],
   "source": [
    "## District 4\n",
    "\n",
    "import os \n",
    "bootstrap_samples_dir = 'bootstrap_samples_new_dis4'\n",
    "\n",
    "# List all files in the directory\n",
    "bootstrap_files = os.listdir(bootstrap_samples_dir)\n",
    "it = 0\n",
    "\n",
    "algo_works = 0\n",
    "data_samples = []\n",
    "\n",
    "# Loop over each file and load it as a DataFrame\n",
    "for file in bootstrap_files:\n",
    "    start = time.time()\n",
    "    \n",
    "    stop = False\n",
    "    it += 1\n",
    "    if it > 100:\n",
    "        break\n",
    "\n",
    "    sample_file_path = os.path.join(bootstrap_samples_dir, file)\n",
    "    \n",
    "    df = pd.read_csv(sample_file_path)\n",
    "\n",
    "    # Initialize a dictionary to store the counts of each ballot type as strings\n",
    "    ballot_counts = {}\n",
    "    #Q = 19141.75\n",
    "\n",
    "    # Iterate through the DataFrame rows\n",
    "    for index, row in df.iterrows():\n",
    "        # Initialize an empty list to store valid candidates\n",
    "        valid_candidates = []\n",
    "        \n",
    "        # Iterate through columns Choice_1 to Choice_6\n",
    "        for i in range(1, 7):\n",
    "            candidate = row[f'Choice_{i}']\n",
    "            if candidate in candidates_mapping.keys():\n",
    "                valid_candidates.append(candidates_mapping[candidate])\n",
    "\n",
    "        # Check if the ballot is empty (no valid candidates)\n",
    "        if valid_candidates:  \n",
    "            ballot_type = ''.join(valid_candidates)\n",
    "\n",
    "            # Add the weight to the count for this ballot type in the dictionary\n",
    "            ballot_counts[ballot_type] = ballot_counts.get(ballot_type, 0) + 1\n",
    "            \n",
    "            \n",
    "    surplusA = {}\n",
    "    A_original = get_new_dict(ballot_counts)['A']\n",
    "    A_needs = Q - A_original\n",
    "    for cand in 'EFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "        fil_data = {}\n",
    "        for key, value in ballot_counts.items():\n",
    "            \n",
    "            new_key = ''.join(char for char in key if char not in 'EDFGHIJKLMNOPQRSTUVWXYZabcd'.replace(cand, \"\"))\n",
    "            \n",
    "            fil_data[new_key] =   fil_data.get(new_key, 0) + value\n",
    "\n",
    "        fil_data.pop('', None)\n",
    "        C_set = {}\n",
    "        for cand_spl in 'BC':\n",
    "            for key, value in ballot_counts.items():\n",
    "                if key[0] in 'EDFGHIJKLMNOPQRSTUVWXYZabcd'.replace(cand, \"\"):\n",
    "                    if cand_spl in key:\n",
    "                        if 'A' in key and key.index('A')>key.index(cand_spl):\n",
    "                            C_set[cand_spl] = C_set.get(cand_spl, 0) + value\n",
    "\n",
    "        AtransfersL = 0 \n",
    "        for key, value in fil_data.items():\n",
    "            if key[0] == 'A':\n",
    "                if len(key)>1 and key[1] in 'EDFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "                    AtransfersL = AtransfersL + value\n",
    "            \n",
    "        SV0 = min(10, get_new_dict(fil_data)['A'] - Q )\n",
    "        #print(SV0)\n",
    "        #print(SV0* (AtransfersL)/(SV0+A_original))\n",
    "        surplusA[cand] = SV0* (AtransfersL)/(SV0+A_original) - min(get_new_dict(fil_data)['B']+C_set['B'], get_new_dict(fil_data)['C']+C_set['C'])#, get_new_dict(fil_data)['D']+C_set['D'])+A_needs\n",
    "            \n",
    "    final_dict = {}\n",
    "    another_dict = {}\n",
    "    for cand in 'EFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "        letter_counts ={}\n",
    "        \n",
    "        #strict_support\n",
    "        for key, value in ballot_counts.items():\n",
    "            i = 0\n",
    "            newset = []\n",
    "            if key and key[0] not in ['A']:\n",
    "                while key[i] in 'AEDFGHIJKLMNOPQRSTUVWXYZabcd':\n",
    "                    newset.append(key[i])\n",
    "                    i=i+1\n",
    "                    if i >= len(key):\n",
    "                        break\n",
    "\n",
    "            new_key = ''.join(char for char in newset)\n",
    "            if cand in new_key:\n",
    "                if cand in letter_counts:\n",
    "                    letter_counts[cand] += value\n",
    "                else:\n",
    "                    letter_counts[cand] = value\n",
    "        final_dict[cand] =    -  round(surplusA[cand]+letter_counts[cand], 2)\n",
    "\n",
    "    maxdev = min(final_dict, key=final_dict.get)   \n",
    "\n",
    "    #print(final_dict)\n",
    "    print(round(final_dict[maxdev]/76563*100,2))\n",
    "    rt, dt, collection = STV_optimal_result_simple(list(candidates_mapping.values()), ballot_counts, 3, Q)\n",
    "    results, subresults = return_main_sub(rt)\n",
    "    candidates_reduced, group, stop = remove_irrelevent(ballot_counts, results[-7:], \n",
    "                results[:4], 76563*0.096, 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcd')\n",
    "    \n",
    "    print(f\"Iteration {it}: Candidates = {candidates_reduced}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Republican Primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time =  860.0913059711456\n",
      "862 1000\n",
      "{'AB': [0, []], 'AC': [22.0, {'E': 22.0}], 'AD': [26.0, {'D': 4.0, 'E': 22.0}]}\n"
     ]
    }
   ],
   "source": [
    "## REpublican primary case analysis \n",
    "\n",
    "\n",
    "# Create a mapping from candidate names to variables\n",
    "candidates_mapping = {\n",
    "    \"Trump\": \"A\",\n",
    "    \"Haley\": \"B\",\n",
    "    \"Ramaswamy\": \"C\",\n",
    "    \"DeSantis\": \"D\",\n",
    "    \"Christie\":\"E\",\n",
    "    \"Pence\": \"F\",\n",
    "    \"Scott\": \"G\",\n",
    "    \"Hurd\": \"H\",\n",
    "    \"Hutchinson\": \"I\",\n",
    "    \"Youngkin\": \"J\",\n",
    "    \"Burgum\": \"K\",\n",
    "    \"Elder\": \"L\",\n",
    "    \"Suarez\": \"M\",\n",
    "}\n",
    "# final: bootstrap_samples_dir = 'bootstrap_samples_new_3'\n",
    "\n",
    "bootstrap_samples_dir = 'bootstrap_samples_new_3'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = \"primary_final_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# List all files in the directory\n",
    "bootstrap_files = os.listdir(bootstrap_samples_dir)\n",
    "it=0\n",
    "budget = 800*0.05-1 #4.75%\n",
    "\n",
    "algo_works = 0\n",
    "\n",
    "data_samples = []\n",
    "start = time.time()\n",
    "# Loop over each file and load it as a DataFrame\n",
    "for file in bootstrap_files:\n",
    "    \n",
    "    it=it+1\n",
    "    sample_file_path = os.path.join(bootstrap_samples_dir, file)\n",
    "    \n",
    "    df = pd.read_csv(sample_file_path)\n",
    "    \n",
    "    #df = df.drop(columns = ['record', 'QBASE'])\n",
    "\n",
    "    # Initialize a dictionary to store the counts of each ballot type as strings\n",
    "    ballot_counts = {}\n",
    "    Q = 800\n",
    "\n",
    "    # Iterate through the DataFrame rows\n",
    "    for index, row in df.iterrows():\n",
    "        # Initialize an empty list to store valid candidates\n",
    "        valid_candidates = []\n",
    "\n",
    "        # Iterate through columns rank1 to rank5\n",
    "        for i in range(1, 14):\n",
    "            candidate = row[f'rank{i}']\n",
    "            valid_candidates.append(candidates_mapping[candidate])\n",
    "\n",
    "\n",
    "        ballot_type = ''.join(valid_candidates)\n",
    "\n",
    "        # Use the 'weight' column to determine the number of voters for this ballot type\n",
    "        weight = row['weight']\n",
    "\n",
    "        # Add the weight to the count for this ballot type in the dictionary\n",
    "        if ballot_type not in ballot_counts:\n",
    "            ballot_counts[ballot_type] = weight\n",
    "        else:\n",
    "            ballot_counts[ballot_type] += weight\n",
    "            \n",
    "    #df['weight'] = df['weight']*800/df['weight'].sum()\n",
    "    \n",
    "    results = IRV_optimal_result(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M'], ballot_counts)\n",
    "    #print(results)\n",
    "    \n",
    "    candidates, group, stop = remove_irrelevent( ballot_counts, results[-7:], \n",
    "                results[:6], budget, 'ABCDEFGHIJKLM')\n",
    "    if stop == False:\n",
    "        candidates, group, stop = remove_irrelevent( ballot_counts, results[-7:], \n",
    "                results[:7], budget, 'ABCDEFGHIJKLM')\n",
    "        \n",
    "    if stop == False:\n",
    "        candidates, group, stop = remove_irrelevent( ballot_counts, results[-7:], \n",
    "                results[:8], budget, 'ABCDEFGHIJKLM')\n",
    "    \n",
    "    if stop==True:\n",
    "        \n",
    "        algo_works = algo_works+1\n",
    "\n",
    "        # Initialize a dictionary for filtered data\n",
    "        filtered_data = {}\n",
    "\n",
    "        # Remove letters {G, H, I, J, K, L} while retaining the rest of the string\n",
    "        for key, value in ballot_counts.items():\n",
    "            new_key = ''.join(char for char in key if char not in group)\n",
    "\n",
    "            filtered_data[new_key] =   filtered_data.get(new_key, 0) + value\n",
    "        filtered_data.pop('', None)\n",
    "        aggre_v_dict_new = get_new_dict(filtered_data)\n",
    "\n",
    "        k=1\n",
    "        Q = round(sum(aggre_v_dict_new [candidate] for candidate in candidates)/(k+1)+1,3)+400\n",
    "\n",
    "        strats_frame = reach_any_winners_campaign(candidates, 2, Q, filtered_data , budget)\n",
    "        data_samples.append(strats_frame)\n",
    "        save_path = os.path.join(output_dir, f\"iteration_{it}.json\")\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump({\"iteration\": it, \"strats_frame\": strats_frame}, f, indent=4)\n",
    "            \n",
    "    \n",
    "end = time.time()    \n",
    "print('total time = ' , end - start)\n",
    "print(algo_works, it)\n",
    "print(strats_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory where JSON files were saved\n",
    "output_dir = \"primary_final_results_3_percent\"  # Replace with your actual directory\n",
    "\n",
    "# Initialize an empty list to store data samples\n",
    "data_samples = []\n",
    "\n",
    "# Get all JSON files in the output directory\n",
    "json_files = sorted([f for f in os.listdir(output_dir) if f.startswith(\"iteration_\") and f.endswith(\".json\")])\n",
    "\n",
    "# Load data from each JSON file\n",
    "for file in json_files:\n",
    "    file_path = os.path.join(output_dir, file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        data_samples.append(data[\"strats_frame\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis of strategies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACD': {'D': 85, 'A': 1}, 'ABD': {'D': 1}}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Initialize dictionaries for analysis\n",
    "winning_combinations_frequency = defaultdict(int)\n",
    "additional_votes_needed = defaultdict(lambda: defaultdict(int))\n",
    "vote_addition_frequency = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Analyze each sample\n",
    "for sample in data_samples:\n",
    "    for combination, (value, details) in sample.items():\n",
    "        # Winning combinations\n",
    "        if value == 0:\n",
    "            winning_combinations_frequency[combination] += 1\n",
    "        else:\n",
    "            # Additional votes needed\n",
    "            additional_votes_needed[combination][value] += 1\n",
    "            if isinstance(details, dict):\n",
    "                for candidate, votes in details.items():\n",
    "                    # Frequency of vote addition to each candidate\n",
    "                    vote_addition_frequency[combination][candidate] += 1\n",
    "\n",
    "# Convert defaultdict to regular dict for cleaner output\n",
    "winning_combinations_frequency = dict(winning_combinations_frequency)\n",
    "additional_votes_needed = {k: dict(v) for k, v in additional_votes_needed.items()}\n",
    "vote_addition_frequency = {k: dict(v) for k, v in vote_addition_frequency.items()}\n",
    "\n",
    "#winning_combinations_frequency, additional_votes_needed, \n",
    "vote_addition_frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACD': {'Single-ranked: D': 85,\n",
       "  'Single-ranked: A': 1,\n",
       "  'Combination: A & D': 1},\n",
       " 'ABD': {'Single-ranked: D': 1}}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "# Initialize dictionary for detailed vote addition frequency\n",
    "detailed_vote_addition_frequency = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Analyze each sample in data_samples\n",
    "for sample in data_samples:\n",
    "    for combination, (value, details) in sample.items():\n",
    "        if value > 0 and isinstance(details, dict):\n",
    "            # Count single candidate additions\n",
    "            for candidate in details:\n",
    "                if len(candidate) == 1:  # Single candidate\n",
    "                    detailed_vote_addition_frequency[combination][f\"Single-ranked: {candidate}\"] += 1\n",
    "                else:  # Multi-ranked\n",
    "                    detailed_vote_addition_frequency[combination][f\"Multi-ranked: {candidate}\"] += 1\n",
    "\n",
    "            # Count combinations of separate additions\n",
    "            if len(details) > 1:\n",
    "                separate_candidates = [candidate for candidate in details if len(candidate) == 1]\n",
    "                for num in range(2, len(separate_candidates) + 1):\n",
    "                    for combo in combinations(separate_candidates, num):\n",
    "                        combo_key = \" & \".join(sorted(combo))\n",
    "                        detailed_vote_addition_frequency[combination][f\"Combination: {combo_key}\"] += 1\n",
    "\n",
    "# Convert defaultdict to regular dict for cleaner output\n",
    "formatted_detailed_vote_addition_frequency = {k: dict(v) for k, v in detailed_vote_addition_frequency.items()}\n",
    "\n",
    "formatted_detailed_vote_addition_frequency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ABC': 100})"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a counter to track the frequency of candidates winning with 0 additions\n",
    "winning_frequency = Counter()\n",
    "\n",
    "# Iterate through each entry in the data\n",
    "for entry in data_samples:\n",
    "    for candidate, values in entry.items():\n",
    "        # Check if the additional votes required is 0\n",
    "        if values[0] == 0:\n",
    "            # Increment the count for this candidate\n",
    "            winning_frequency[candidate] += 1\n",
    "\n",
    "winning_frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of additions = {'ACD': 0.172, 'ABD': 0.0}\n",
      "average additions = {'ACD': 5.642, 'ABD': 5.932}\n",
      "win using additions = Counter({'ACD': 85, 'ABD': 1})\n",
      "Winning frequncy =  Counter({'ABC': 100})\n",
      "win by hook or crook for moe 577.895 = {'ACD': 85.0, 'ABD': 1.0}\n",
      "average_additions_percentage =  {'ACD': 5.642, 'ABD': 5.932}\n",
      "{'ACD': 5.207, 'ABD': 5.932}\n",
      "{'ACD': 5.998, 'ABD': 5.932}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Initialize dictionaries to track the total additions and the count of instances for each combination\n",
    "total_additions = Counter()\n",
    "win_with_additions = Counter()\n",
    "min_additions = {}\n",
    "max_additions = {}\n",
    "total_votes = 77036\n",
    "\n",
    "\n",
    "# Iterate through each entry in the data\n",
    "for entry in data_samples:\n",
    "    for candidate, values in entry.items():\n",
    "        additions, details = values\n",
    "        # Check if the combination is not winning (additions not 0)\n",
    "        if additions != 0:\n",
    "            # Sum the additions made for each candidate within the combination\n",
    "            total_additions_for_candidate = sum(details.values())\n",
    "            # Update the total additions and count for this combination\n",
    "            total_additions[candidate] += total_additions_for_candidate\n",
    "            win_with_additions[candidate] += 1\n",
    "            # Track minimum and maximum additions for each candidate\n",
    "            if candidate not in min_additions:\n",
    "                min_additions[candidate] = total_additions_for_candidate\n",
    "                max_additions[candidate] = total_additions_for_candidate\n",
    "            else:\n",
    "                min_additions[candidate] = min(min_additions[candidate], total_additions_for_candidate)\n",
    "                max_additions[candidate] = max(max_additions[candidate], total_additions_for_candidate)\n",
    "\n",
    "# Calculate the average additions for each combination\n",
    "average_additions = {candidate: total_additions[candidate] / win_with_additions[candidate] \n",
    "                     for candidate in total_additions}\n",
    "# Calculate the standard deviation of additions for each combination\n",
    "std_dev_additions = {}\n",
    "for candidate in total_additions:\n",
    "    additions_list = []\n",
    "    for entry in data_samples:\n",
    "        if candidate in entry:\n",
    "            additions, details = entry[candidate]\n",
    "            if additions != 0:\n",
    "                additions_list.append(sum(details.values()))\n",
    "    std_dev_additions[candidate] = np.std(additions_list)\n",
    "\n",
    "percent_std_dev_additions = {candidate: round(value/total_votes*100, 3) for candidate, value in std_dev_additions.items()}\n",
    "print('Standard deviation of additions =', percent_std_dev_additions)\n",
    "\n",
    "win_hook_or_crook  = {candidate: round((win_with_additions[candidate]+winning_frequency[candidate])\n",
    "                                       /algo_works*100,3) for candidate in win_with_additions}\n",
    "\n",
    "average_additions_percentage = {candidate: round(total_additions[candidate]*100 / (total_votes*win_with_additions[candidate]) ,3)\n",
    "                     for candidate in total_additions}\n",
    "min_additions_percetage = {candidate: round(min_additions[candidate]*100 / total_votes, 3) for candidate in min_additions}\n",
    "max_additions_percetage = {candidate: round(max_additions[candidate]*100 / total_votes, 3) for candidate in max_additions}\n",
    "\n",
    "print('average additions =', average_additions_percentage)\n",
    "print('win using additions =', win_with_additions)\n",
    "print('Winning frequncy = ', winning_frequency)\n",
    "print('win by hook or crook for moe', (budget+1)/8, '=',  win_hook_or_crook)\n",
    "print('average_additions_percentage = ', average_additions_percentage)\n",
    "print(min_additions_percetage)\n",
    "print(max_additions_percetage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACD': {'D': {'D': 100.0}, 'AD': {'D': 99.98, 'A': 0.02}},\n",
       " 'ABD': {'D': {'D': 100.0}}}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reinitialize the dictionary to track the frequencies of each unique type of addition for each combination\n",
    "addition_frequencies = defaultdict(Counter)\n",
    "\n",
    "# Function to extract individual candidates from the addition types\n",
    "def extract_candidates(addition_types):\n",
    "    candidates = set()\n",
    "    for addition in addition_types:\n",
    "        for candidate in addition:\n",
    "            candidates.add(candidate)\n",
    "    return ''.join(sorted(candidates))\n",
    "\n",
    "# Iterate through each entry in the data\n",
    "for entry in data_samples:\n",
    "    for candidate, values in entry.items():\n",
    "        additions, details = values\n",
    "        # Check if the combination is not winning (additions not 0)\n",
    "        if additions != 0:\n",
    "            # Extract individual candidates from the addition types\n",
    "            addition_category = extract_candidates(details.keys())\n",
    "            # Increment the frequency for this category of addition\n",
    "            addition_frequencies[candidate][addition_category] += 1\n",
    "\n",
    "# Calculate the within-category distribution of additions\n",
    "within_category_distribution = defaultdict(lambda: defaultdict(Counter))\n",
    "\n",
    "for candidate, categories in addition_frequencies.items():\n",
    "    for category, count in categories.items():\n",
    "        for entry in data_samples:\n",
    "            if candidate in entry:\n",
    "                additions, details = entry[candidate]\n",
    "                if additions != 0:\n",
    "                    addition_category = extract_candidates(details.keys())\n",
    "                    if addition_category == category:\n",
    "                        for addition_type, votes in details.items():\n",
    "                            within_category_distribution[candidate][category][addition_type] += votes\n",
    "\n",
    "# Convert counts to percentages within each category\n",
    "within_category_percentage_distribution = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for candidate, categories in within_category_distribution.items():\n",
    "    for category, additions in categories.items():\n",
    "        total_votes = sum(additions.values())\n",
    "        for addition_type, votes in additions.items():\n",
    "            within_category_percentage_distribution[candidate][category][addition_type] = (votes / total_votes) * 100\n",
    "\n",
    "# Convert defaultdict to regular dict for better readability\n",
    "within_category_percentage_distribution = {k: {sub_k: {inner_k: round(inner_v, 2) for inner_k, inner_v in sub_v.items()} for sub_k, sub_v in v.items()} for k, v in within_category_percentage_distribution.items()}\n",
    "within_category_percentage_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([223.,  55.,  69.,  87., 159., 108.,  94.,  73.,  58.,  73.]),\n",
       " array([ 0. ,  2.2,  4.4,  6.6,  8.8, 11. , 13.2, 15.4, 17.6, 19.8, 22. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# Function to calculate the average non-zero deviations for each dictionary\n",
    "def average_non_zero_deviations(data_samples):\n",
    "    averages = []\n",
    "\n",
    "    for dict_item in data_samples:\n",
    "        total = 0\n",
    "        count = 0\n",
    "        for key, value in dict_item.items():\n",
    "            deviation = value[0]\n",
    "            if deviation != 0:\n",
    "                total += deviation\n",
    "                count += 1\n",
    "        average = total / count if count != 0 else 0\n",
    "        averages.append(average)\n",
    "\n",
    "    return averages\n",
    "\n",
    "# Calculate the averages\n",
    "average_deviations = average_non_zero_deviations(data_samples)\n",
    "average_deviations.count(0)\n",
    "print(len(average_deviations))\n",
    "plt.hist(average_deviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
